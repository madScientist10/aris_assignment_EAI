{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbb56dd1-38bf-44a9-9c43-bb999fe15b16",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-09-15 23:43:19.854931: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-15 23:43:19.854988: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-15 23:43:19.856224: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-15 23:43:19.863795: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-15 23:43:20.841246: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "from trl import ORPOConfig, ORPOTrainer, setup_chat_format\n",
    "from lm_eval import evaluator, tasks\n",
    "from lm_eval.models.huggingface import HFLM\n",
    "\n",
    "# api_key=\"MY_WANDB_API_KEY\" # WANDB API KEY\n",
    "# wandb.login(key=api_key)\n",
    "# wandb.init(project='assignment-edgerunner-aris')\n",
    "\n",
    "# Set torch dtype and attention implementation\n",
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    !pip install -qqq flash-attn\n",
    "    torch_dtype = torch.bfloat16\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "else:\n",
    "    torch_dtype = torch.float16\n",
    "    attn_implementation = \"eager\"\n",
    "    \n",
    "# BNB config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# LoRA config\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n",
    ")\n",
    "\n",
    "model1_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "model2_name = \"edgerunner-ai/EdgeRunner-Tactical-7B\"\n",
    "tuned_model1_name = \"ORPO-Llama-3.1-8B-Instruct-GSM8K\"\n",
    "tuned_model2_name = \"ORPO-EdgeRunner-Tactical-7B-GSM8K\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c7c730-a419-46f6-92f7-a8b87351d17a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Model 1 (Llama 3.1) Evaluation GSM8K ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abaad636-4b23-4def-91cc-11a6674b2a2c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: gsm8k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-16:04:23:35,445 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-09-16:04:23:35,445 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'load_in_4bit': True}\n",
      "2024-09-16:04:23:35,447 INFO     [huggingface.py:138] Device not specified\n",
      "2024-09-16:04:23:35,447 INFO     [huggingface.py:139] Cuda Available? True\n",
      "2024-09-16:04:23:35,799 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.15s/it]\n",
      "2024-09-16:04:23:40,900 WARNING  [big_modeling.py:451] You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "2024-09-16:04:23:42,127 INFO     [__init__.py:491] `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.\n",
      "2024-09-16:04:24:49,586 WARNING  [evaluator.py:267] Overwriting default num_fewshot of gsm8k from 5 to 8\n",
      "2024-09-16:04:24:49,587 INFO     [evaluator.py:279] Setting fewshot random generator seed to 1234\n",
      "2024-09-16:04:24:49,598 INFO     [task.py:428] Building contexts for gsm8k on rank 0...\n",
      "100%|██████████| 1319/1319 [00:09<00:00, 134.32it/s]\n",
      "2024-09-16:04:24:59,458 INFO     [evaluator.py:485] Running generate_until requests\n",
      "Running generate_until requests:   0%|          | 0/1319 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed argument batch_size = auto. Detecting largest batch size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determined Largest batch size: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Running generate_until requests: 100%|██████████| 1319/1319 [3:14:08<00:00,  8.83s/it] \n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "fatal: detected dubious ownership in repository at '/mnt/batch/tasks/shared/LS_root/mounts/clusters/aris1/code/Users/mlstudio-notebooks'\n",
      "To add an exception for this directory, call:\n",
      "\n",
      "\tgit config --global --add safe.directory /mnt/batch/tasks/shared/LS_root/mounts/clusters/aris1/code/Users/mlstudio-notebooks\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gsm8k': {'alias': 'gsm8k', 'exact_match,strict-match': 0.7543593631539045, 'exact_match_stderr,strict-match': 0.011857183603902225, 'exact_match,flexible-extract': 0.7702805155420773, 'exact_match_stderr,flexible-extract': 0.011586857544997503}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del model2\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "def evaluate_model(model, task=\"gsm8k\"):\n",
    "    print(f\"Task: {task}\")\n",
    "    \n",
    "    results = evaluator.simple_evaluate(\n",
    "        model=\"hf\",\n",
    "        model_args=f\"pretrained={model},load_in_4bit=True\",\n",
    "        tasks=[task],\n",
    "        batch_size='auto',\n",
    "        device='auto',\n",
    "        #limit = 10,\n",
    "        num_fewshot = 8, # for paper\n",
    "        apply_chat_template=True,\n",
    "        fewshot_as_multiturn=True\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "task = 'gsm8k'\n",
    "results = evaluate_model(model1_name, task)\n",
    "print(results['results'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd3da46-5d09-453b-9a73-f0cda276b52b",
   "metadata": {},
   "source": [
    "#### Model 2 (EdgeRunner Tactical) Evaluation GSM8K ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63b0660-33f9-498a-97e8-5f17702927e0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15:23:43:30,646 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-09-15:23:43:30,647 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'edgerunner-ai/EdgeRunner-Tactical-7B', 'load_in_4bit': True}\n",
      "2024-09-15:23:43:30,715 INFO     [huggingface.py:138] Device not specified\n",
      "2024-09-15:23:43:30,716 INFO     [huggingface.py:139] Cuda Available? True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: gsm8k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15:23:43:31,115 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:08<00:00,  1.19s/it]\n",
      "2024-09-15:23:43:40,763 WARNING  [big_modeling.py:451] You shouldn't move a model that is dispatched using accelerate hooks.\n",
      "2024-09-15:23:43:41,317 INFO     [__init__.py:491] `group` and `group_alias` keys in TaskConfigs are deprecated and will be removed in v0.4.5 of lm_eval. The new `tag` field will be used to allow for a shortcut to a group of tasks one does not wish to aggregate metrics across. `group`s which aggregate across subtasks must be only defined in a separate group config file, which will be the official way to create groups that support cross-task aggregation as in `mmlu`. Please see the v0.4.4 patch notes and our documentation: https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/new_task_guide.md#advanced-group-configs for more information.\n",
      "2024-09-15:23:45:04,629 WARNING  [evaluator.py:267] Overwriting default num_fewshot of gsm8k from 5 to 8\n",
      "2024-09-15:23:45:04,631 INFO     [evaluator.py:279] Setting fewshot random generator seed to 1234\n",
      "2024-09-15:23:45:04,640 INFO     [task.py:428] Building contexts for gsm8k on rank 0...\n",
      "100%|██████████| 1319/1319 [00:09<00:00, 133.93it/s]\n",
      "2024-09-15:23:45:14,528 INFO     [evaluator.py:485] Running generate_until requests\n",
      "Running generate_until requests:   0%|          | 0/1319 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed argument batch_size = auto. Detecting largest batch size\n",
      "Determined Largest batch size: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n",
      "Running generate_until requests: 100%|██████████| 1319/1319 [4:38:15<00:00, 12.66s/it]  \n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "fatal: detected dubious ownership in repository at '/mnt/batch/tasks/shared/LS_root/mounts/clusters/aris1/code/Users/mlstudio-notebooks'\n",
      "To add an exception for this directory, call:\n",
      "\n",
      "\tgit config --global --add safe.directory /mnt/batch/tasks/shared/LS_root/mounts/clusters/aris1/code/Users/mlstudio-notebooks\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gsm8k': {'alias': 'gsm8k', 'exact_match,strict-match': 0.012130401819560273, 'exact_match_stderr,strict-match': 0.0030152942428909504, 'exact_match,flexible-extract': 0.6338134950720242, 'exact_match_stderr,flexible-extract': 0.01327010023874883}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del model1\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "# EdgeRunner-Tactical-7B does not fit into the GPU in this compute instance.\n",
    "# So I will load it in 4bit precision. However, evaluation in this quantized model might not be accurate,\n",
    "# since when loading and using the model with this configuration it produced incoherent text jargon.\n",
    "def evaluate_model(model, task=\"gsm8k\"):\n",
    "    print(f\"Task: {task}\")\n",
    "    \n",
    "    results = evaluator.simple_evaluate(\n",
    "        model=\"hf\",\n",
    "        model_args=f\"pretrained={model},load_in_4bit=True\",\n",
    "        tasks=[task],\n",
    "        batch_size='auto',\n",
    "        device='auto',\n",
    "        #limit = 10,\n",
    "        num_fewshot = 8, # 8 for paper\n",
    "        apply_chat_template=True,\n",
    "        fewshot_as_multiturn=True\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "task = 'gsm8k'\n",
    "results = evaluate_model(model2_name, task)\n",
    "print(results['results'])\n",
    "\n",
    "# Flush memory\n",
    "try:\n",
    "    del model2\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3798fd28-5c53-4345-89b4-5c07814aade5",
   "metadata": {},
   "source": [
    "#### Model 1 (Llama 3.1) Fine-Tune ORPO ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0221569-84ef-4fb3-9985-d3561bf3462b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:07<00:00, 16.78s/it]\n"
     ]
    }
   ],
   "source": [
    "model1 = AutoModelForCausalLM.from_pretrained(model1_name, \n",
    "                                              quantization_config=bnb_config,\n",
    "                                              attn_implementation=attn_implementation,\n",
    "                                              device_map=\"auto\", cache_dir = './models/')\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(model1_name)\n",
    "# tokenizer1.pad_token = tokenizer1.eos_token\n",
    "model1, tokenizer1 = setup_chat_format(model1, tokenizer1)                                             \n",
    "model1 = prepare_model_for_kbit_training(model1)\n",
    "\n",
    "\n",
    "dataset_name = \"mlabonne/orpo-dpo-mix-40k\"\n",
    "dataset = load_dataset(dataset_name, split=\"all\")\n",
    "dataset = dataset.shuffle(seed=1234).select(range(2000)) # Only use some samples for assignment time & resources constraints\n",
    "\n",
    "def format_chat_template(row):\n",
    "    row[\"chosen\"] = tokenizer1.apply_chat_template(row[\"chosen\"], tokenize=False)\n",
    "    row[\"rejected\"] = tokenizer1.apply_chat_template(row[\"rejected\"], tokenize=False)\n",
    "    return row\n",
    "\n",
    "dataset = dataset.map(\n",
    "    format_chat_template,\n",
    "    num_proc= os.cpu_count(),\n",
    ")\n",
    "dataset = dataset.train_test_split(test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "103da279-948c-4b61-baa0-06a6402b86f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/trl/trainer/orpo_trainer.py:255: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 1980/1980 [00:08<00:00, 223.00 examples/s]\n",
      "Map: 100%|██████████| 20/20 [00:00<00:00, 214.11 examples/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 2:34:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "      <th>Nll Loss</th>\n",
       "      <th>Log Odds Ratio</th>\n",
       "      <th>Log Odds Chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>1.185100</td>\n",
       "      <td>1.170097</td>\n",
       "      <td>34.660700</td>\n",
       "      <td>0.577000</td>\n",
       "      <td>0.577000</td>\n",
       "      <td>-0.080159</td>\n",
       "      <td>-0.081189</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>-0.811894</td>\n",
       "      <td>-0.801589</td>\n",
       "      <td>-1.192466</td>\n",
       "      <td>-0.760882</td>\n",
       "      <td>1.101702</td>\n",
       "      <td>-0.683950</td>\n",
       "      <td>0.084238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>1.158200</td>\n",
       "      <td>1.067999</td>\n",
       "      <td>34.634200</td>\n",
       "      <td>0.577000</td>\n",
       "      <td>0.577000</td>\n",
       "      <td>-0.070551</td>\n",
       "      <td>-0.070821</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>-0.708212</td>\n",
       "      <td>-0.705506</td>\n",
       "      <td>-0.739886</td>\n",
       "      <td>-0.458917</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>-0.686829</td>\n",
       "      <td>0.097613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>0.938800</td>\n",
       "      <td>1.032679</td>\n",
       "      <td>34.633500</td>\n",
       "      <td>0.577000</td>\n",
       "      <td>0.577000</td>\n",
       "      <td>-0.068220</td>\n",
       "      <td>-0.071094</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>-0.710940</td>\n",
       "      <td>-0.682201</td>\n",
       "      <td>-0.630925</td>\n",
       "      <td>-0.364262</td>\n",
       "      <td>0.967068</td>\n",
       "      <td>-0.656107</td>\n",
       "      <td>0.173828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>1.021572</td>\n",
       "      <td>34.634800</td>\n",
       "      <td>0.577000</td>\n",
       "      <td>0.577000</td>\n",
       "      <td>-0.067609</td>\n",
       "      <td>-0.071633</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>-0.716327</td>\n",
       "      <td>-0.676089</td>\n",
       "      <td>-0.549493</td>\n",
       "      <td>-0.308409</td>\n",
       "      <td>0.957033</td>\n",
       "      <td>-0.645399</td>\n",
       "      <td>0.202548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>1.230800</td>\n",
       "      <td>1.018366</td>\n",
       "      <td>34.633200</td>\n",
       "      <td>0.577000</td>\n",
       "      <td>0.577000</td>\n",
       "      <td>-0.067445</td>\n",
       "      <td>-0.072256</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>-0.722560</td>\n",
       "      <td>-0.674452</td>\n",
       "      <td>-0.535899</td>\n",
       "      <td>-0.299210</td>\n",
       "      <td>0.954504</td>\n",
       "      <td>-0.638618</td>\n",
       "      <td>0.220906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./Llama_FT_Adapters/tokenizer_config.json',\n",
       " './Llama_FT_Adapters/special_tokens_map.json',\n",
       " './Llama_FT_Adapters/tokenizer.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orpo_args = ORPOConfig(\n",
    "    learning_rate=8e-6,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    max_length=1024,\n",
    "    max_prompt_length=512,\n",
    "    beta=0.1,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    num_train_epochs=1, # Just 1 epoch for the assignment\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    report_to=\"wandb\",\n",
    "    output_dir=\"./results/\",\n",
    "    seed = 1234\n",
    ")\n",
    "\n",
    "trainer = ORPOTrainer(\n",
    "    model=model1,\n",
    "    args=orpo_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    peft_config=peft_config,\n",
    "    tokenizer=tokenizer1,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save adapters after training\n",
    "trainer.model.save_pretrained(\"./Llama_FT_Adapters/\")\n",
    "tokenizer1.save_pretrained(\"./Llama_FT_Adapters/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4810fb4f-859d-482e-915f-784df9ee7557",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.36s/it]\n",
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:336: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n",
      "\n",
      "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s].05G [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|          | 0.00/4.65G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:   0%|          | 4.06M/1.05G [00:00<00:25, 40.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|          | 3.51M/4.65G [00:00<02:12, 35.0MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:   2%|▏         | 16.0M/1.05G [00:00<00:19, 54.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|          | 16.0M/4.65G [00:00<01:30, 51.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|          | 32.0M/4.65G [00:00<01:08, 67.9MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:   3%|▎         | 32.0M/1.05G [00:00<00:16, 62.1MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   5%|▍         | 48.0M/1.05G [00:00<00:15, 63.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|          | 48.0M/4.65G [00:00<01:14, 61.7MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:   6%|▌         | 64.0M/1.05G [00:01<00:16, 61.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|▏         | 64.0M/4.65G [00:01<01:16, 60.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2%|▏         | 80.0M/4.65G [00:01<01:03, 71.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:   8%|▊         | 80.0M/1.05G [00:01<00:14, 69.0MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   9%|▉         | 96.0M/1.05G [00:01<00:13, 71.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2%|▏         | 96.0M/4.65G [00:01<01:03, 71.6MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  11%|█         | 112M/1.05G [00:01<00:12, 74.6MB/s] \u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2%|▏         | 112M/4.65G [00:01<01:05, 69.5MB/s] \u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  12%|█▏        | 128M/1.05G [00:01<00:12, 74.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3%|▎         | 128M/4.65G [00:02<01:13, 61.8MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  14%|█▎        | 144M/1.05G [00:02<00:12, 74.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3%|▎         | 144M/4.65G [00:02<01:09, 65.2MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  15%|█▌        | 160M/1.05G [00:02<00:13, 67.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3%|▎         | 160M/4.65G [00:02<01:08, 65.5MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  17%|█▋        | 176M/1.05G [00:02<00:12, 67.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4%|▍         | 176M/4.65G [00:02<01:09, 64.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4%|▍         | 192M/4.65G [00:02<01:01, 72.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4%|▍         | 208M/4.65G [00:03<01:06, 66.9MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  18%|█▊        | 192M/1.05G [00:03<00:20, 41.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   5%|▍         | 224M/4.65G [00:03<01:08, 64.7MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  20%|█▉        | 208M/1.05G [00:03<00:17, 49.0MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  21%|██▏       | 224M/1.05G [00:03<00:14, 57.1MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   5%|▌         | 240M/4.65G [00:03<01:15, 58.5MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  23%|██▎       | 240M/1.05G [00:03<00:12, 62.6MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  24%|██▍       | 256M/1.05G [00:04<00:11, 68.1MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  26%|██▌       | 272M/1.05G [00:04<00:11, 69.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6%|▌         | 256M/4.65G [00:04<01:38, 44.7MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  27%|██▋       | 288M/1.05G [00:04<00:10, 72.7MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  29%|██▉       | 304M/1.05G [00:04<00:09, 77.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6%|▌         | 272M/4.65G [00:04<01:45, 41.6MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  30%|███       | 320M/1.05G [00:04<00:10, 69.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6%|▌         | 288M/4.65G [00:04<01:31, 47.7MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  32%|███▏      | 336M/1.05G [00:05<00:09, 74.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7%|▋         | 304M/4.65G [00:05<01:24, 51.7MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  34%|███▎      | 352M/1.05G [00:05<00:09, 73.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7%|▋         | 320M/4.65G [00:05<01:18, 55.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  35%|███▌      | 368M/1.05G [00:05<00:09, 72.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7%|▋         | 336M/4.65G [00:05<01:13, 58.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  37%|███▋      | 384M/1.05G [00:05<00:09, 71.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8%|▊         | 352M/4.65G [00:05<01:13, 58.5MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  38%|███▊      | 400M/1.05G [00:06<00:08, 73.9MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  40%|███▉      | 416M/1.05G [00:06<00:09, 66.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8%|▊         | 368M/4.65G [00:06<01:22, 52.1MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  41%|████      | 432M/1.05G [00:06<00:09, 65.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8%|▊         | 384M/4.65G [00:06<01:21, 52.3MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  43%|████▎     | 448M/1.05G [00:06<00:09, 61.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9%|▊         | 400M/4.65G [00:06<01:19, 53.8MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  44%|████▍     | 464M/1.05G [00:07<00:09, 62.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9%|▉         | 416M/4.65G [00:07<01:14, 56.6MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  46%|████▌     | 480M/1.05G [00:07<00:08, 64.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9%|▉         | 432M/4.65G [00:07<01:03, 66.1MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  47%|████▋     | 496M/1.05G [00:07<00:07, 70.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10%|▉         | 448M/4.65G [00:07<01:09, 60.3MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  49%|████▊     | 512M/1.05G [00:07<00:08, 66.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10%|▉         | 464M/4.65G [00:07<01:01, 68.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  50%|█████     | 528M/1.05G [00:08<00:07, 68.1MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10%|█         | 480M/4.65G [00:08<01:06, 62.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  52%|█████▏    | 544M/1.05G [00:08<00:07, 68.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11%|█         | 496M/4.65G [00:08<01:07, 61.7MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  53%|█████▎    | 560M/1.05G [00:08<00:07, 64.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11%|█         | 512M/4.65G [00:08<01:01, 67.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11%|█▏        | 528M/4.65G [00:08<01:03, 65.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  55%|█████▍    | 576M/1.05G [00:08<00:09, 50.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  12%|█▏        | 544M/4.65G [00:09<01:05, 63.1MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  56%|█████▋    | 592M/1.05G [00:09<00:08, 53.0MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  12%|█▏        | 560M/4.65G [00:09<01:00, 67.2MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  58%|█████▊    | 608M/1.05G [00:09<00:07, 57.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  12%|█▏        | 576M/4.65G [00:09<00:58, 70.3MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  59%|█████▉    | 624M/1.05G [00:09<00:07, 57.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  13%|█▎        | 592M/4.65G [00:09<00:58, 69.5MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  61%|██████    | 640M/1.05G [00:10<00:06, 59.4MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  62%|██████▏   | 656M/1.05G [00:10<00:06, 59.8MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  64%|██████▍   | 672M/1.05G [00:10<00:05, 63.2MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  65%|██████▌   | 688M/1.05G [00:10<00:06, 58.6MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  67%|██████▋   | 704M/1.05G [00:11<00:05, 58.9MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  69%|██████▊   | 720M/1.05G [00:11<00:05, 60.4MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  70%|███████   | 736M/1.05G [00:11<00:05, 55.5MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  72%|███████▏  | 752M/1.05G [00:11<00:04, 64.1MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  13%|█▎        | 608M/4.65G [00:12<03:39, 18.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  73%|███████▎  | 768M/1.05G [00:12<00:04, 58.0MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  13%|█▎        | 624M/4.65G [00:12<02:52, 23.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  75%|███████▍  | 784M/1.05G [00:12<00:04, 56.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  14%|█▍        | 640M/4.65G [00:12<02:17, 29.1MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  76%|███████▌  | 800M/1.05G [00:12<00:03, 62.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  14%|█▍        | 656M/4.65G [00:12<01:53, 35.3MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  78%|███████▊  | 816M/1.05G [00:12<00:03, 66.7MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  14%|█▍        | 672M/4.65G [00:13<01:39, 40.1MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  79%|███████▉  | 832M/1.05G [00:13<00:03, 64.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  15%|█▍        | 688M/4.65G [00:13<01:24, 47.1MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  81%|████████  | 848M/1.05G [00:13<00:03, 66.5MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  82%|████████▏ | 864M/1.05G [00:13<00:02, 66.0MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  15%|█▌        | 704M/4.65G [00:13<01:19, 49.7MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  84%|████████▍ | 880M/1.05G [00:13<00:02, 67.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  15%|█▌        | 720M/4.65G [00:13<01:12, 54.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  16%|█▌        | 736M/4.65G [00:14<01:07, 57.9MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  85%|████████▌ | 896M/1.05G [00:14<00:02, 63.3MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  87%|████████▋ | 912M/1.05G [00:14<00:01, 73.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  16%|█▌        | 752M/4.65G [00:14<01:04, 60.1MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  88%|████████▊ | 928M/1.05G [00:14<00:01, 74.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  17%|█▋        | 768M/4.65G [00:14<00:55, 69.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  17%|█▋        | 784M/4.65G [00:14<00:54, 70.6MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  90%|████████▉ | 944M/1.05G [00:14<00:01, 66.1MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  17%|█▋        | 800M/4.65G [00:14<00:56, 67.7MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  91%|█████████▏| 960M/1.05G [00:15<00:01, 60.0MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  93%|█████████▎| 976M/1.05G [00:15<00:01, 67.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  18%|█▊        | 816M/4.65G [00:15<01:05, 58.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  18%|█▊        | 832M/4.65G [00:15<01:00, 63.3MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  94%|█████████▍| 992M/1.05G [00:15<00:01, 58.0MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  96%|█████████▌| 1.01G/1.05G [00:15<00:00, 61.4MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  97%|█████████▋| 1.02G/1.05G [00:16<00:00, 61.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  18%|█▊        | 848M/4.65G [00:16<01:26, 44.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  19%|█▊        | 864M/4.65G [00:16<01:14, 50.9MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  99%|█████████▉| 1.04G/1.05G [00:16<00:00, 60.8MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors: 100%|██████████| 1.05G/1.05G [00:16<00:00, 63.3MB/s][A\u001b[A\n",
      "\n",
      "\n",
      "Upload 2 LFS files:  50%|█████     | 1/2 [00:16<00:16, 16.78s/it]:16<00:59, 63.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  20%|█▉        | 912M/4.65G [00:16<00:53, 70.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  20%|█▉        | 928M/4.65G [00:17<00:59, 63.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  20%|██        | 944M/4.65G [00:17<00:59, 62.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  21%|██        | 960M/4.65G [00:17<00:56, 65.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  21%|██        | 976M/4.65G [00:17<00:55, 66.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  21%|██▏       | 992M/4.65G [00:18<00:51, 71.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  22%|██▏       | 1.01G/4.65G [00:18<00:45, 79.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  22%|██▏       | 1.02G/4.65G [00:18<00:49, 73.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  22%|██▏       | 1.04G/4.65G [00:18<00:51, 69.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  23%|██▎       | 1.06G/4.65G [00:18<00:51, 70.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  23%|██▎       | 1.07G/4.65G [00:19<00:54, 65.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  23%|██▎       | 1.09G/4.65G [00:19<00:58, 61.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24%|██▎       | 1.10G/4.65G [00:19<00:51, 68.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24%|██▍       | 1.12G/4.65G [00:19<00:46, 75.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24%|██▍       | 1.14G/4.65G [00:20<00:48, 72.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  25%|██▍       | 1.15G/4.65G [00:20<00:51, 68.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  25%|██▌       | 1.17G/4.65G [00:20<00:49, 70.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  25%|██▌       | 1.18G/4.65G [00:20<00:50, 69.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  26%|██▌       | 1.20G/4.65G [00:21<01:21, 42.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  26%|██▌       | 1.22G/4.65G [00:21<01:12, 47.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  26%|██▋       | 1.23G/4.65G [00:21<01:03, 54.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  27%|██▋       | 1.25G/4.65G [00:22<01:00, 56.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  27%|██▋       | 1.26G/4.65G [00:22<00:57, 59.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  28%|██▊       | 1.28G/4.65G [00:22<00:54, 61.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  28%|██▊       | 1.30G/4.65G [00:23<01:00, 55.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  28%|██▊       | 1.31G/4.65G [00:23<01:02, 53.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  29%|██▊       | 1.33G/4.65G [00:23<00:55, 60.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  29%|██▉       | 1.34G/4.65G [00:23<01:01, 53.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  29%|██▉       | 1.36G/4.65G [00:24<00:58, 56.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  30%|██▉       | 1.38G/4.65G [00:24<00:57, 56.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  30%|██▉       | 1.39G/4.65G [00:24<00:52, 62.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  30%|███       | 1.41G/4.65G [00:24<00:52, 62.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  31%|███       | 1.42G/4.65G [00:25<00:57, 55.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  31%|███       | 1.44G/4.65G [00:25<00:59, 53.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  31%|███▏      | 1.46G/4.65G [00:25<00:54, 58.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  32%|███▏      | 1.47G/4.65G [00:26<01:13, 43.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  32%|███▏      | 1.49G/4.65G [00:26<01:04, 49.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  32%|███▏      | 1.50G/4.65G [00:27<01:25, 37.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  33%|███▎      | 1.52G/4.65G [00:27<01:12, 43.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  33%|███▎      | 1.54G/4.65G [00:27<01:03, 49.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  33%|███▎      | 1.55G/4.65G [00:31<04:08, 12.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  34%|███▎      | 1.57G/4.65G [00:31<03:05, 16.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  34%|███▍      | 1.58G/4.65G [00:31<02:20, 21.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  34%|███▍      | 1.60G/4.65G [00:32<01:56, 26.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  35%|███▍      | 1.62G/4.65G [00:32<01:33, 32.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  35%|███▌      | 1.63G/4.65G [00:32<01:16, 39.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  35%|███▌      | 1.65G/4.65G [00:32<01:06, 45.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  36%|███▌      | 1.66G/4.65G [00:32<00:59, 49.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  36%|███▌      | 1.68G/4.65G [00:33<00:58, 51.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  36%|███▋      | 1.70G/4.65G [00:33<00:54, 54.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  37%|███▋      | 1.71G/4.65G [00:33<00:49, 58.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  37%|███▋      | 1.73G/4.65G [00:34<00:53, 54.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  37%|███▋      | 1.74G/4.65G [00:34<00:55, 52.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  38%|███▊      | 1.76G/4.65G [00:34<00:51, 56.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  38%|███▊      | 1.78G/4.65G [00:34<00:44, 64.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  39%|███▊      | 1.79G/4.65G [00:34<00:40, 70.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  39%|███▉      | 1.81G/4.65G [00:35<00:55, 51.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  39%|███▉      | 1.82G/4.65G [00:35<00:48, 58.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  40%|███▉      | 1.84G/4.65G [00:35<00:45, 61.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  40%|███▉      | 1.86G/4.65G [00:36<00:47, 58.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  40%|████      | 1.87G/4.65G [00:36<00:51, 54.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  41%|████      | 1.89G/4.65G [00:36<00:48, 56.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  41%|████      | 1.90G/4.65G [00:37<00:51, 53.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  41%|████▏     | 1.92G/4.65G [00:37<00:43, 63.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  42%|████▏     | 1.94G/4.65G [00:37<00:44, 61.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  42%|████▏     | 1.95G/4.65G [00:37<00:41, 65.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  42%|████▏     | 1.97G/4.65G [00:38<00:45, 58.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  43%|████▎     | 1.98G/4.65G [00:38<00:47, 56.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  43%|████▎     | 2.00G/4.65G [00:38<00:45, 58.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  43%|████▎     | 2.02G/4.65G [00:38<00:43, 60.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  44%|████▎     | 2.03G/4.65G [00:39<00:42, 60.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  44%|████▍     | 2.05G/4.65G [00:39<00:43, 60.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  44%|████▍     | 2.06G/4.65G [00:39<00:40, 64.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  45%|████▍     | 2.08G/4.65G [00:39<00:37, 68.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  45%|████▌     | 2.10G/4.65G [00:40<00:36, 69.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  45%|████▌     | 2.11G/4.65G [00:40<00:34, 72.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  46%|████▌     | 2.13G/4.65G [00:40<00:37, 67.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  46%|████▌     | 2.14G/4.65G [00:40<00:36, 69.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  46%|████▋     | 2.16G/4.65G [00:41<00:40, 61.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  47%|████▋     | 2.18G/4.65G [00:41<00:37, 65.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  47%|████▋     | 2.19G/4.65G [00:41<00:39, 61.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  47%|████▋     | 2.21G/4.65G [00:41<00:42, 57.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  48%|████▊     | 2.22G/4.65G [00:42<00:40, 59.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  48%|████▊     | 2.24G/4.65G [00:42<00:43, 55.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  48%|████▊     | 2.26G/4.65G [00:42<00:46, 51.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  49%|████▉     | 2.27G/4.65G [00:43<00:44, 53.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  49%|████▉     | 2.29G/4.65G [00:43<00:42, 55.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  50%|████▉     | 2.30G/4.65G [00:43<00:46, 50.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  50%|████▉     | 2.32G/4.65G [00:43<00:41, 55.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  50%|█████     | 2.34G/4.65G [00:44<00:42, 54.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  51%|█████     | 2.35G/4.65G [00:44<00:43, 52.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  51%|█████     | 2.37G/4.65G [00:44<00:38, 59.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  51%|█████     | 2.38G/4.65G [00:45<00:37, 60.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  52%|█████▏    | 2.40G/4.65G [00:45<00:39, 57.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  52%|█████▏    | 2.42G/4.65G [00:45<00:37, 59.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  52%|█████▏    | 2.43G/4.65G [00:46<00:43, 51.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  53%|█████▎    | 2.45G/4.65G [00:46<00:39, 56.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  53%|█████▎    | 2.46G/4.65G [00:46<00:36, 59.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  53%|█████▎    | 2.48G/4.65G [00:46<00:33, 65.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  54%|█████▎    | 2.50G/4.65G [00:46<00:33, 64.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  54%|█████▍    | 2.51G/4.65G [00:47<00:29, 71.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  54%|█████▍    | 2.53G/4.65G [00:47<00:31, 68.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  55%|█████▍    | 2.54G/4.65G [00:47<00:36, 57.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  55%|█████▌    | 2.56G/4.65G [00:48<00:39, 52.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  55%|█████▌    | 2.58G/4.65G [00:48<00:38, 54.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  56%|█████▌    | 2.59G/4.65G [00:48<00:35, 58.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  56%|█████▌    | 2.61G/4.65G [00:48<00:31, 64.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  56%|█████▋    | 2.62G/4.65G [00:49<00:32, 61.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  57%|█████▋    | 2.64G/4.65G [00:49<00:29, 69.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  57%|█████▋    | 2.66G/4.65G [00:49<00:31, 64.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  57%|█████▋    | 2.67G/4.65G [00:49<00:30, 65.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  58%|█████▊    | 2.69G/4.65G [00:49<00:28, 69.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  58%|█████▊    | 2.70G/4.65G [00:50<00:28, 68.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  58%|█████▊    | 2.72G/4.65G [00:50<00:30, 63.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  59%|█████▉    | 2.74G/4.65G [00:50<00:29, 64.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  59%|█████▉    | 2.75G/4.65G [00:50<00:27, 70.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  60%|█████▉    | 2.77G/4.65G [00:51<00:30, 62.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  60%|█████▉    | 2.78G/4.65G [00:51<00:29, 62.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  60%|██████    | 2.80G/4.65G [00:51<00:29, 63.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  61%|██████    | 2.82G/4.65G [00:52<00:31, 58.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  61%|██████    | 2.83G/4.65G [00:52<00:28, 64.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  61%|██████    | 2.85G/4.65G [00:52<00:34, 51.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  62%|██████▏   | 2.86G/4.65G [00:52<00:29, 61.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  62%|██████▏   | 2.88G/4.65G [00:53<00:30, 58.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  62%|██████▏   | 2.90G/4.65G [00:53<00:30, 56.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  63%|██████▎   | 2.91G/4.65G [00:53<00:29, 59.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  63%|██████▎   | 2.93G/4.65G [00:53<00:26, 65.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  63%|██████▎   | 2.94G/4.65G [00:54<00:25, 67.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  64%|██████▎   | 2.96G/4.65G [00:54<00:28, 60.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  64%|██████▍   | 2.98G/4.65G [00:54<00:26, 63.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  64%|██████▍   | 2.99G/4.65G [00:54<00:26, 61.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  65%|██████▍   | 3.01G/4.65G [00:55<00:28, 58.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  65%|██████▌   | 3.02G/4.65G [00:55<00:30, 54.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  65%|██████▌   | 3.04G/4.65G [00:55<00:27, 58.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  66%|██████▌   | 3.06G/4.65G [00:56<00:27, 57.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  66%|██████▌   | 3.07G/4.65G [00:56<00:27, 56.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  66%|██████▋   | 3.09G/4.65G [00:56<00:26, 59.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  67%|██████▋   | 3.10G/4.65G [00:56<00:23, 65.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  67%|██████▋   | 3.12G/4.65G [00:56<00:20, 74.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  67%|██████▋   | 3.14G/4.65G [00:57<00:20, 74.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  68%|██████▊   | 3.15G/4.65G [00:57<00:21, 71.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  68%|██████▊   | 3.17G/4.65G [00:57<00:19, 76.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  68%|██████▊   | 3.18G/4.65G [00:57<00:22, 64.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  69%|██████▉   | 3.20G/4.65G [00:58<00:21, 68.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  69%|██████▉   | 3.22G/4.65G [00:58<00:22, 64.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  69%|██████▉   | 3.23G/4.65G [00:58<00:21, 64.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  70%|██████▉   | 3.25G/4.65G [00:58<00:20, 69.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  70%|███████   | 3.26G/4.65G [00:59<00:21, 63.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  71%|███████   | 3.28G/4.65G [00:59<00:23, 59.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  71%|███████   | 3.30G/4.65G [00:59<00:24, 54.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  71%|███████   | 3.31G/4.65G [01:00<00:23, 56.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  72%|███████▏  | 3.33G/4.65G [01:00<00:21, 61.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  72%|███████▏  | 3.34G/4.65G [01:00<00:31, 41.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  72%|███████▏  | 3.36G/4.65G [01:01<00:27, 47.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  73%|███████▎  | 3.38G/4.65G [01:01<00:23, 53.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  73%|███████▎  | 3.39G/4.65G [01:01<00:22, 56.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  73%|███████▎  | 3.41G/4.65G [01:01<00:19, 65.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  74%|███████▎  | 3.42G/4.65G [01:02<00:18, 65.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  74%|███████▍  | 3.44G/4.65G [01:02<00:18, 64.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  74%|███████▍  | 3.46G/4.65G [01:02<00:16, 71.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  75%|███████▍  | 3.47G/4.65G [01:02<00:16, 71.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  75%|███████▍  | 3.49G/4.65G [01:02<00:17, 67.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  75%|███████▌  | 3.50G/4.65G [01:03<00:19, 57.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  76%|███████▌  | 3.52G/4.65G [01:03<00:17, 64.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  76%|███████▌  | 3.54G/4.65G [01:03<00:21, 51.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  76%|███████▋  | 3.55G/4.65G [01:04<00:20, 54.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  77%|███████▋  | 3.57G/4.65G [01:04<00:20, 52.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  77%|███████▋  | 3.58G/4.65G [01:04<00:17, 61.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  77%|███████▋  | 3.60G/4.65G [01:04<00:16, 64.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  78%|███████▊  | 3.62G/4.65G [01:05<00:16, 64.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  78%|███████▊  | 3.63G/4.65G [01:05<00:14, 68.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  78%|███████▊  | 3.65G/4.65G [01:05<00:14, 70.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  79%|███████▉  | 3.66G/4.65G [01:05<00:15, 63.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  79%|███████▉  | 3.68G/4.65G [01:06<00:16, 60.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  79%|███████▉  | 3.70G/4.65G [01:06<00:15, 61.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  80%|███████▉  | 3.71G/4.65G [01:06<00:15, 59.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  80%|████████  | 3.73G/4.65G [01:06<00:15, 61.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  80%|████████  | 3.74G/4.65G [01:07<00:20, 44.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  81%|████████  | 3.76G/4.65G [01:07<00:16, 53.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  81%|████████  | 3.78G/4.65G [01:08<00:18, 48.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  82%|████████▏ | 3.79G/4.65G [01:08<00:16, 52.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  82%|████████▏ | 3.81G/4.65G [01:08<00:13, 60.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  82%|████████▏ | 3.82G/4.65G [01:09<00:20, 40.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  83%|████████▎ | 3.84G/4.65G [01:09<00:17, 45.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  83%|████████▎ | 3.86G/4.65G [01:09<00:16, 49.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  83%|████████▎ | 3.87G/4.65G [01:10<00:14, 54.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  84%|████████▎ | 3.89G/4.65G [01:10<00:15, 49.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  84%|████████▍ | 3.90G/4.65G [01:10<00:14, 51.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  84%|████████▍ | 3.92G/4.65G [01:10<00:13, 55.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  85%|████████▍ | 3.94G/4.65G [01:11<00:11, 62.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  85%|████████▍ | 3.95G/4.65G [01:11<00:10, 65.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  85%|████████▌ | 3.97G/4.65G [01:11<00:10, 65.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  86%|████████▌ | 3.98G/4.65G [01:11<00:10, 66.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  86%|████████▌ | 4.00G/4.65G [01:12<00:10, 63.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  86%|████████▋ | 4.02G/4.65G [01:12<00:08, 71.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  87%|████████▋ | 4.03G/4.65G [01:12<00:08, 72.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  87%|████████▋ | 4.05G/4.65G [01:12<00:08, 71.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  87%|████████▋ | 4.06G/4.65G [01:12<00:08, 72.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  88%|████████▊ | 4.08G/4.65G [01:13<00:07, 74.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  88%|████████▊ | 4.10G/4.65G [01:13<00:08, 62.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  88%|████████▊ | 4.11G/4.65G [01:13<00:08, 66.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  89%|████████▊ | 4.13G/4.65G [01:13<00:07, 67.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  89%|████████▉ | 4.14G/4.65G [01:14<00:07, 70.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  89%|████████▉ | 4.16G/4.65G [01:14<00:07, 66.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  90%|████████▉ | 4.18G/4.65G [01:14<00:06, 74.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  90%|█████████ | 4.19G/4.65G [01:14<00:07, 61.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  90%|█████████ | 4.21G/4.65G [01:17<00:26, 17.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  91%|█████████ | 4.22G/4.65G [01:17<00:19, 21.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  91%|█████████ | 4.24G/4.65G [01:17<00:15, 27.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  91%|█████████▏| 4.26G/4.65G [01:18<00:11, 33.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  92%|█████████▏| 4.27G/4.65G [01:18<00:09, 40.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  92%|█████████▏| 4.29G/4.65G [01:23<00:41, 8.73MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  93%|█████████▎| 4.30G/4.65G [01:23<00:29, 11.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  93%|█████████▎| 4.32G/4.65G [01:23<00:21, 15.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  93%|█████████▎| 4.34G/4.65G [01:24<00:16, 19.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  94%|█████████▎| 4.35G/4.65G [01:24<00:12, 24.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  94%|█████████▍| 4.37G/4.65G [01:24<00:09, 31.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  94%|█████████▍| 4.38G/4.65G [01:25<00:07, 36.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  95%|█████████▍| 4.40G/4.65G [01:25<00:05, 43.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  95%|█████████▍| 4.42G/4.65G [01:25<00:05, 47.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  95%|█████████▌| 4.43G/4.65G [01:25<00:04, 49.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  96%|█████████▌| 4.45G/4.65G [01:26<00:03, 57.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  96%|█████████▌| 4.46G/4.65G [01:26<00:03, 62.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  96%|█████████▋| 4.48G/4.65G [01:26<00:02, 58.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  97%|█████████▋| 4.50G/4.65G [01:26<00:02, 60.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  97%|█████████▋| 4.51G/4.65G [01:27<00:02, 58.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  97%|█████████▋| 4.53G/4.65G [01:27<00:02, 61.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  98%|█████████▊| 4.54G/4.65G [01:27<00:01, 67.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  98%|█████████▊| 4.56G/4.65G [01:27<00:01, 73.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  98%|█████████▊| 4.58G/4.65G [01:27<00:01, 67.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  99%|█████████▊| 4.59G/4.65G [01:28<00:01, 49.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  99%|█████████▉| 4.61G/4.65G [01:28<00:00, 46.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  99%|█████████▉| 4.62G/4.65G [01:28<00:00, 56.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors: 100%|██████████| 4.65G/4.65G [01:29<00:00, 52.0MB/s]\u001b[A\u001b[A\n",
      "Upload 2 LFS files: 100%|██████████| 2/2 [01:29<00:00, 44.84s/it]\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "2024-09-15:15:33:53,146 WARNING  [hf_api.py:3800] No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/huggingscientist10/ORPO-Llama-3.1-8B-Instruct-GSM8K/commit/e1ca7c943c750c0d2ded3ac35d9331c53b21661d', commit_message='Upload tokenizer', commit_description='', oid='e1ca7c943c750c0d2ded3ac35d9331c53b21661d', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flush memory\n",
    "try:\n",
    "    del model1\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "# Reload tokenizer and model\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(model1_name)\n",
    "model1 = AutoModelForCausalLM.from_pretrained(\n",
    "    model1_name,\n",
    "    return_dict=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation,\n",
    ")\n",
    "model1, tokenizer1 = setup_chat_format(model1, tokenizer1)\n",
    "\n",
    "# Merge adapter with base model\n",
    "merged_model = PeftModel.from_pretrained(model1, \"./Llama_FT_Adapters/\")\n",
    "merged_model = merged_model.merge_and_unload()\n",
    "\n",
    "# Save model and tokenizer\n",
    "merged_model.save_pretrained(tuned_model1_name)\n",
    "tokenizer1.save_pretrained(tuned_model1_name)\n",
    "\n",
    "# Push tuned model to HF\n",
    "merged_model.push_to_hub(tuned_model1_name, use_temp_dir=True, token = \"\") # write HF token\n",
    "tokenizer1.push_to_hub(tuned_model1_name, use_temp_dir=True, token = \"\") # write HF token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb5030-e2c5-42fe-ab15-ce53fa172b0c",
   "metadata": {},
   "source": [
    "#### Model 2 (EdgeRunner Tactical) Fine-Tune ORPO ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5f3e5f-fe1e-4478-ab96-093272dcdd4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [02:09<00:00, 18.56s/it]\n"
     ]
    }
   ],
   "source": [
    "# Flush memory\n",
    "try:\n",
    "    del model1\n",
    "    del merged_model\n",
    "    del trainer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "# Initialize Model 2/EdgeRunner Tactical\n",
    "model2 = AutoModelForCausalLM.from_pretrained(model2_name,attn_implementation=attn_implementation,\n",
    "                torch_dtype=torch.bfloat16, device_map=\"auto\", cache_dir = './models/')\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(model2_name)\n",
    "    \n",
    "dataset_name = \"mlabonne/orpo-dpo-mix-40k\"\n",
    "dataset = load_dataset(dataset_name, split=\"all\")\n",
    "dataset = dataset.shuffle(seed=1234).select(range(2000)) # Only use 1000 samples for quick demo\n",
    "\n",
    "def format_chat_template(row):\n",
    "    row[\"chosen\"] = tokenizer2.apply_chat_template(row[\"chosen\"], tokenize=False)\n",
    "    row[\"rejected\"] = tokenizer2.apply_chat_template(row[\"rejected\"], tokenize=False)\n",
    "    return row\n",
    "\n",
    "dataset = dataset.map(\n",
    "    format_chat_template,\n",
    "    num_proc= os.cpu_count(),\n",
    ")\n",
    "dataset = dataset.train_test_split(test_size=0.01) # Re-split dataset since the chat template formating removed train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b61bae32-228d-4446-bc7b-bceaddedaa8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.9/site-packages/trl/trainer/orpo_trainer.py:255: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 1980/1980 [00:10<00:00, 195.35 examples/s]\n",
      "Map: 100%|██████████| 20/20 [00:00<00:00, 140.96 examples/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [495/495 2:13:17, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "      <th>Nll Loss</th>\n",
       "      <th>Log Odds Ratio</th>\n",
       "      <th>Log Odds Chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.941700</td>\n",
       "      <td>1.262900</td>\n",
       "      <td>37.682100</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>-0.100109</td>\n",
       "      <td>-0.104098</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>-1.040976</td>\n",
       "      <td>-1.001090</td>\n",
       "      <td>-1.526038</td>\n",
       "      <td>-0.868249</td>\n",
       "      <td>1.193946</td>\n",
       "      <td>-0.689545</td>\n",
       "      <td>0.056690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>1.039800</td>\n",
       "      <td>1.134898</td>\n",
       "      <td>37.672200</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>-0.085545</td>\n",
       "      <td>-0.084231</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>-0.001314</td>\n",
       "      <td>-0.842309</td>\n",
       "      <td>-0.855447</td>\n",
       "      <td>-1.520530</td>\n",
       "      <td>-0.849269</td>\n",
       "      <td>1.063321</td>\n",
       "      <td>-0.715768</td>\n",
       "      <td>-0.005385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>1.060400</td>\n",
       "      <td>1.104771</td>\n",
       "      <td>37.651100</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>-0.082312</td>\n",
       "      <td>-0.080231</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>-0.002081</td>\n",
       "      <td>-0.802306</td>\n",
       "      <td>-0.823116</td>\n",
       "      <td>-1.531466</td>\n",
       "      <td>-0.871727</td>\n",
       "      <td>1.032694</td>\n",
       "      <td>-0.720779</td>\n",
       "      <td>-0.015191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>1.117000</td>\n",
       "      <td>1.091131</td>\n",
       "      <td>37.652900</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>-0.080975</td>\n",
       "      <td>-0.078231</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>-0.002744</td>\n",
       "      <td>-0.782310</td>\n",
       "      <td>-0.809751</td>\n",
       "      <td>-1.530538</td>\n",
       "      <td>-0.872586</td>\n",
       "      <td>1.018570</td>\n",
       "      <td>-0.725612</td>\n",
       "      <td>-0.023911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>0.910900</td>\n",
       "      <td>1.086137</td>\n",
       "      <td>37.658600</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>-0.080373</td>\n",
       "      <td>-0.077437</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.002936</td>\n",
       "      <td>-0.774367</td>\n",
       "      <td>-0.803728</td>\n",
       "      <td>-1.529951</td>\n",
       "      <td>-0.874795</td>\n",
       "      <td>1.013409</td>\n",
       "      <td>-0.727286</td>\n",
       "      <td>-0.026317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./EdgeRunner_FT_Adapters/tokenizer_config.json',\n",
       " './EdgeRunner_FT_Adapters/special_tokens_map.json',\n",
       " './EdgeRunner_FT_Adapters/vocab.json',\n",
       " './EdgeRunner_FT_Adapters/merges.txt',\n",
       " './EdgeRunner_FT_Adapters/added_tokens.json',\n",
       " './EdgeRunner_FT_Adapters/tokenizer.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orpo_args = ORPOConfig(\n",
    "    learning_rate=8e-6,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    max_length=1024,\n",
    "    max_prompt_length=512,\n",
    "    beta=0.1,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    num_train_epochs=1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    report_to=\"wandb\",\n",
    "    output_dir=\"./results/\",\n",
    "    seed = 1234\n",
    ")\n",
    "\n",
    "trainer = ORPOTrainer(\n",
    "    model=model2,\n",
    "    args=orpo_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    peft_config=peft_config,\n",
    "    tokenizer=tokenizer2,\n",
    ")\n",
    "trainer.train()\n",
    "trainer.model.save_pretrained(\"./EdgeRunner_FT_Adapters/\")\n",
    "tokenizer2.save_pretrained(\"./EdgeRunner_FT_Adapters/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9651df0-3ffd-419e-acdc-87edba6e8b6d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.13it/s]\n",
      "model-00001-of-00004.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]\n",
      "model-00002-of-00004.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   0%|          | 0.00/4.33G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 4.49M/4.87G [00:00<01:48, 44.9MB/s]\n",
      "model-00002-of-00004.safetensors:   0%|          | 3.28M/4.93G [00:00<02:30, 32.8MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:   1%|          | 5.64M/1.09G [00:00<00:19, 56.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 13.0M/4.87G [00:00<01:11, 68.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   0%|          | 12.2M/4.93G [00:00<01:14, 65.8MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:   1%|▏         | 14.6M/1.09G [00:00<00:14, 75.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   0%|          | 10.8M/4.33G [00:00<01:11, 60.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:   2%|▏         | 23.9M/1.09G [00:00<00:12, 83.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   0%|          | 16.8M/4.33G [00:00<01:31, 47.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|          | 19.8M/4.87G [00:00<01:55, 42.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   1%|          | 30.6M/4.33G [00:00<00:55, 77.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:   3%|▎         | 32.3M/1.09G [00:00<00:16, 64.3MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   1%|          | 31.8M/4.93G [00:00<01:07, 72.9MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|          | 32.0M/4.87G [00:00<01:28, 54.7MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:   4%|▍         | 48.0M/1.09G [00:00<00:15, 67.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   1%|          | 39.1M/4.33G [00:00<01:18, 54.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|          | 48.0M/4.87G [00:00<01:16, 63.2MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:   6%|▌         | 64.0M/1.09G [00:00<00:13, 76.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|▏         | 64.0M/4.87G [00:01<01:14, 64.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:   7%|▋         | 80.0M/1.09G [00:01<00:13, 76.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   1%|▏         | 64.0M/4.33G [00:01<01:09, 61.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   1%|▏         | 64.0M/4.93G [00:01<01:35, 51.1MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:   8%|▊         | 89.7M/1.09G [00:01<00:12, 80.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   2%|▏         | 78.0M/4.33G [00:01<00:55, 77.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 80.0M/4.87G [00:01<01:11, 66.9MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:   9%|▉         | 98.0M/1.09G [00:01<00:14, 70.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 96.0M/4.87G [00:01<01:10, 67.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  10%|█         | 112M/1.09G [00:01<00:14, 67.4MB/s] \u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   2%|▏         | 86.5M/4.93G [00:01<01:46, 45.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   2%|▏         | 96.0M/4.33G [00:01<01:16, 55.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   2%|▏         | 96.0M/4.93G [00:01<01:43, 46.6MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  12%|█▏        | 128M/1.09G [00:01<00:13, 68.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 112M/4.87G [00:01<01:26, 55.3MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   2%|▏         | 112M/4.93G [00:01<01:28, 54.6MB/s] \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 128M/4.87G [00:02<01:18, 60.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  13%|█▎        | 144M/1.09G [00:02<00:15, 60.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   3%|▎         | 144M/4.33G [00:02<01:00, 69.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 144M/4.87G [00:02<01:16, 61.5MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  15%|█▍        | 160M/1.09G [00:02<00:16, 57.0MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   3%|▎         | 144M/4.93G [00:02<01:16, 62.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   4%|▎         | 160M/4.33G [00:02<01:00, 68.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 160M/4.87G [00:02<01:17, 60.8MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   3%|▎         | 160M/4.93G [00:02<01:10, 68.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   4%|▍         | 176M/4.33G [00:02<00:59, 69.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▎         | 176M/4.87G [00:02<01:09, 67.3MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   4%|▎         | 176M/4.93G [00:02<01:00, 78.4MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   4%|▍         | 192M/4.93G [00:03<00:59, 79.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 192M/4.87G [00:03<01:12, 64.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   5%|▍         | 208M/4.33G [00:03<00:59, 69.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 208M/4.87G [00:03<01:10, 65.8MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  19%|█▉        | 208M/1.09G [00:03<00:17, 48.9MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   5%|▍         | 224M/4.93G [00:03<01:01, 76.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▍         | 224M/4.87G [00:03<01:08, 67.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  21%|██        | 224M/1.09G [00:03<00:15, 54.5MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   5%|▍         | 240M/4.93G [00:03<01:04, 73.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▍         | 240M/4.87G [00:03<01:07, 68.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  22%|██▏       | 240M/1.09G [00:03<00:14, 58.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   6%|▌         | 256M/4.33G [00:03<00:54, 75.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 256M/4.87G [00:03<01:04, 71.9MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  24%|██▎       | 256M/1.09G [00:04<00:13, 59.6MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   6%|▌         | 272M/4.93G [00:04<01:01, 76.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 272M/4.87G [00:04<01:07, 68.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  25%|██▌       | 272M/1.09G [00:04<00:12, 62.9MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   6%|▌         | 288M/4.93G [00:04<01:01, 75.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 288M/4.87G [00:04<01:05, 69.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  26%|██▋       | 288M/1.09G [00:04<00:12, 63.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   7%|▋         | 304M/4.33G [00:04<00:54, 73.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 304M/4.87G [00:04<01:06, 68.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   7%|▋         | 320M/4.33G [00:04<00:56, 71.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  28%|██▊       | 304M/1.09G [00:04<00:13, 59.2MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 320M/4.87G [00:04<01:07, 67.1MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  29%|██▉       | 320M/1.09G [00:04<00:11, 68.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 336M/4.87G [00:05<01:02, 72.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   8%|▊         | 352M/4.33G [00:05<00:50, 78.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 352M/4.87G [00:05<01:00, 74.6MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   7%|▋         | 336M/4.93G [00:05<01:40, 45.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   8%|▊         | 368M/4.33G [00:05<00:57, 68.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 368M/4.87G [00:05<01:01, 73.7MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   7%|▋         | 350M/4.93G [00:05<01:23, 55.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   9%|▊         | 377M/4.33G [00:05<00:54, 72.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 375M/4.87G [00:05<01:01, 73.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:   9%|▉         | 385M/4.33G [00:05<00:58, 67.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   7%|▋         | 357M/4.93G [00:05<01:26, 53.0MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 384M/4.87G [00:05<01:07, 66.6MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   7%|▋         | 368M/4.93G [00:05<01:23, 54.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 400M/4.87G [00:06<01:08, 65.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  35%|███▌      | 384M/1.09G [00:06<00:12, 55.5MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   8%|▊         | 384M/4.93G [00:06<01:15, 60.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  10%|▉         | 416M/4.33G [00:06<01:00, 65.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▊         | 416M/4.87G [00:06<01:09, 64.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 432M/4.87G [00:06<01:05, 67.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  38%|███▊      | 416M/1.09G [00:06<00:12, 54.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  10%|█         | 448M/4.33G [00:06<01:00, 64.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 448M/4.87G [00:06<01:10, 63.1MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  40%|███▉      | 432M/1.09G [00:06<00:10, 60.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 464M/4.87G [00:07<01:03, 69.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   8%|▊         | 416M/4.93G [00:07<01:46, 42.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 480M/4.87G [00:07<01:04, 68.1MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   9%|▉         | 432M/4.93G [00:07<01:29, 50.6MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  43%|████▎     | 464M/1.09G [00:07<00:11, 54.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|█         | 496M/4.87G [00:07<01:07, 64.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:   9%|▉         | 448M/4.93G [00:07<01:28, 50.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 512M/4.87G [00:07<01:04, 67.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  11%|█▏        | 496M/4.33G [00:07<01:16, 49.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|█         | 528M/4.87G [00:07<01:01, 71.1MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  46%|████▌     | 496M/1.09G [00:07<00:09, 60.7MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  10%|▉         | 480M/4.93G [00:08<01:13, 61.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 544M/4.87G [00:08<00:58, 74.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  47%|████▋     | 512M/1.09G [00:08<00:08, 68.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  12%|█▏        | 528M/4.33G [00:08<01:05, 57.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  10%|█         | 496M/4.93G [00:08<01:09, 63.7MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█▏        | 560M/4.87G [00:08<00:59, 72.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  13%|█▎        | 544M/4.33G [00:08<00:58, 64.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 576M/4.87G [00:08<01:00, 70.6MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  50%|█████     | 544M/1.09G [00:08<00:08, 67.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  13%|█▎        | 560M/4.33G [00:08<00:55, 68.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  11%|█         | 528M/4.93G [00:08<01:02, 70.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 592M/4.87G [00:08<01:07, 63.7MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  11%|█         | 544M/4.93G [00:09<01:09, 62.8MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  53%|█████▎    | 576M/1.09G [00:09<00:07, 66.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 608M/4.87G [00:09<01:04, 65.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  11%|█▏        | 560M/4.93G [00:09<01:04, 67.4MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  54%|█████▍    | 592M/1.09G [00:09<00:06, 72.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 624M/4.87G [00:09<00:59, 71.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  12%|█▏        | 576M/4.93G [00:09<00:59, 72.8MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  56%|█████▌    | 608M/1.09G [00:09<00:06, 73.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 640M/4.87G [00:09<00:58, 72.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  12%|█▏        | 592M/4.93G [00:09<00:58, 74.3MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  57%|█████▋    | 624M/1.09G [00:09<00:06, 76.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 656M/4.87G [00:09<01:02, 67.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  12%|█▏        | 608M/4.93G [00:09<00:57, 75.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  15%|█▍        | 640M/4.33G [00:09<00:47, 77.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▎        | 670M/4.87G [00:09<00:53, 79.1MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  13%|█▎        | 622M/4.93G [00:09<00:50, 85.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  15%|█▌        | 652M/4.33G [00:09<00:42, 85.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  60%|██████    | 656M/1.09G [00:10<00:05, 72.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 679M/4.87G [00:10<01:05, 64.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  13%|█▎        | 631M/4.93G [00:10<01:07, 63.8MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  61%|██████    | 664M/1.09G [00:10<00:05, 73.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 687M/4.87G [00:10<01:02, 67.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  62%|██████▏   | 672M/1.09G [00:10<00:06, 68.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 695M/4.87G [00:10<01:09, 59.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  13%|█▎        | 640M/4.93G [00:10<01:17, 55.4MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  63%|██████▎   | 688M/1.09G [00:10<00:04, 86.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 704M/4.87G [00:10<01:17, 54.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 720M/4.87G [00:10<01:11, 58.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  16%|█▋        | 704M/4.33G [00:10<01:02, 57.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  65%|██████▍   | 705M/1.09G [00:10<00:06, 55.1MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 736M/4.87G [00:11<01:05, 63.4MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  14%|█▎        | 672M/4.93G [00:11<01:22, 51.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  17%|█▋        | 720M/4.33G [00:11<01:01, 59.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 752M/4.87G [00:11<00:57, 71.9MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  14%|█▍        | 688M/4.93G [00:11<01:16, 55.7MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 768M/4.87G [00:11<00:56, 72.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  17%|█▋        | 736M/4.33G [00:11<01:07, 53.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  69%|██████▉   | 752M/1.09G [00:11<00:04, 67.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  14%|█▍        | 704M/4.93G [00:11<01:12, 58.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  17%|█▋        | 752M/4.33G [00:11<00:59, 60.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  15%|█▍        | 720M/4.93G [00:11<01:06, 63.0MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 784M/4.87G [00:11<01:11, 57.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  18%|█▊        | 768M/4.33G [00:11<01:01, 58.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  15%|█▍        | 736M/4.93G [00:12<01:05, 64.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▋        | 800M/4.87G [00:12<01:10, 57.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  18%|█▊        | 784M/4.33G [00:12<00:56, 62.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 816M/4.87G [00:12<01:09, 58.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  18%|█▊        | 800M/4.33G [00:12<00:55, 63.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  16%|█▌        | 768M/4.93G [00:12<00:56, 73.2MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  74%|███████▎  | 800M/1.09G [00:12<00:04, 57.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  19%|█▉        | 814M/4.33G [00:12<00:46, 75.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  16%|█▌        | 782M/4.93G [00:12<00:49, 84.2MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  75%|███████▍  | 813M/1.09G [00:12<00:04, 67.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 832M/4.87G [00:12<01:11, 56.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  76%|███████▌  | 821M/1.09G [00:12<00:04, 63.9MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  16%|█▌        | 792M/4.93G [00:12<01:01, 67.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  19%|█▉        | 832M/4.33G [00:12<00:53, 65.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 848M/4.87G [00:13<01:17, 51.9MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  16%|█▌        | 800M/4.93G [00:13<01:17, 53.2MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  78%|███████▊  | 848M/1.09G [00:13<00:03, 65.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 864M/4.87G [00:13<01:11, 56.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  17%|█▋        | 816M/4.93G [00:13<01:12, 56.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 880M/4.87G [00:13<01:02, 64.3MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 896M/4.87G [00:13<00:57, 69.1MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  17%|█▋        | 848M/4.93G [00:13<01:04, 62.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▊        | 912M/4.87G [00:13<01:02, 63.0MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  18%|█▊        | 864M/4.93G [00:13<00:59, 68.5MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 928M/4.87G [00:14<01:03, 62.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 944M/4.87G [00:14<00:56, 69.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  84%|████████▍ | 912M/1.09G [00:14<00:03, 54.3MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 960M/4.87G [00:14<00:56, 68.7MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  18%|█▊        | 912M/4.93G [00:14<01:03, 63.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|██        | 976M/4.87G [00:14<00:58, 66.2MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  19%|█▉        | 928M/4.93G [00:14<00:56, 70.7MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  87%|████████▋ | 944M/1.09G [00:15<00:02, 55.6MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|██        | 992M/4.87G [00:15<00:54, 71.6MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.01G/4.87G [00:15<00:54, 70.6MB/s][A\n",
      "model-00002-of-00004.safetensors:  20%|█▉        | 970M/4.93G [00:15<00:49, 79.4MB/s]\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  88%|████████▊ | 960M/1.09G [00:15<00:02, 52.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  20%|█▉        | 864M/4.33G [00:15<03:37, 15.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.02G/4.87G [00:15<01:00, 64.1MB/s][A\n",
      "\n",
      "model-00004-of-00004.safetensors:  90%|████████▉ | 976M/1.09G [00:15<00:01, 55.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.03G/4.87G [00:15<00:54, 70.7MB/s][A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  91%|█████████ | 986M/1.09G [00:15<00:01, 61.0MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|██▏       | 1.04G/4.87G [00:15<01:01, 62.7MB/s][A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  20%|██        | 880M/4.33G [00:15<02:44, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.06G/4.87G [00:16<00:53, 72.0MB/s][A\u001b[A\n",
      "model-00002-of-00004.safetensors:  20%|██        | 1.01G/4.93G [00:16<01:00, 64.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  21%|██        | 896M/4.33G [00:16<01:59, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.07G/4.87G [00:16<00:51, 73.5MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  21%|██        | 1.02G/4.93G [00:16<00:59, 65.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.09G/4.87G [00:16<00:52, 72.4MB/s][A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  94%|█████████▍| 1.02G/1.09G [00:16<00:01, 55.7MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  21%|██        | 1.04G/4.93G [00:16<00:56, 68.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.10G/4.87G [00:16<00:49, 77.0MB/s][A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  95%|█████████▍| 1.03G/1.09G [00:16<00:00, 60.1MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.11G/4.87G [00:16<00:52, 72.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  22%|██▏       | 932M/4.33G [00:16<01:17, 43.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.12G/4.87G [00:16<00:58, 64.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00004-of-00004.safetensors:  97%|█████████▋| 1.06G/1.09G [00:16<00:00, 62.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  22%|██▏       | 944M/4.33G [00:17<01:18, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  21%|██▏       | 1.06G/4.93G [00:17<01:45, 36.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.14G/4.87G [00:17<01:00, 61.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  22%|██▏       | 960M/4.33G [00:17<01:09, 48.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  22%|██▏       | 1.07G/4.93G [00:17<01:17, 49.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|██▎       | 1.15G/4.87G [00:17<00:55, 67.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  22%|██▏       | 972M/4.33G [00:17<00:58, 57.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors: 100%|██████████| 1.09G/1.09G [00:17<00:00, 62.2MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  24%|██▎       | 1.15G/4.87G [00:17<01:01, 60.1MB/s]\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  23%|██▎       | 979M/4.33G [00:17<01:06, 50.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  22%|██▏       | 1.09G/4.93G [00:17<01:11, 53.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.17G/4.87G [00:17<01:04, 57.9MB/s][A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  22%|██▏       | 1.10G/4.93G [00:17<01:11, 53.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.18G/4.87G [00:17<00:53, 68.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  23%|██▎       | 1.12G/4.93G [00:18<01:03, 59.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.20G/4.87G [00:18<00:51, 71.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.22G/4.87G [00:18<00:52, 70.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  24%|██▍       | 1.04G/4.33G [00:18<00:49, 66.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  25%|██▌       | 1.23G/4.87G [00:18<00:54, 67.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.25G/4.87G [00:18<00:49, 73.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  24%|██▎       | 1.17G/4.93G [00:18<01:00, 62.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.26G/4.87G [00:19<00:55, 64.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  25%|██▌       | 1.09G/4.33G [00:19<00:51, 62.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|██▋       | 1.28G/4.87G [00:19<00:52, 68.9MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  24%|██▍       | 1.20G/4.93G [00:19<01:03, 58.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.30G/4.87G [00:19<00:58, 61.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  26%|██▌       | 1.12G/4.33G [00:19<00:50, 64.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.31G/4.87G [00:19<00:50, 70.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  26%|██▌       | 1.14G/4.33G [00:19<00:46, 68.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  25%|██▍       | 1.23G/4.93G [00:20<01:02, 59.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.33G/4.87G [00:20<00:57, 61.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  25%|██▌       | 1.25G/4.93G [00:20<01:00, 60.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.34G/4.87G [00:20<00:55, 64.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  27%|██▋       | 1.18G/4.33G [00:20<00:44, 71.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.36G/4.87G [00:20<00:56, 61.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  28%|██▊       | 1.20G/4.33G [00:20<00:40, 77.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  26%|██▌       | 1.28G/4.93G [00:20<00:55, 66.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.38G/4.87G [00:20<00:55, 63.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  26%|██▋       | 1.30G/4.93G [00:21<00:57, 63.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  28%|██▊       | 1.23G/4.33G [00:21<00:40, 76.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  29%|██▉       | 1.25G/4.33G [00:21<00:44, 69.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  27%|██▋       | 1.31G/4.93G [00:21<01:19, 45.6MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  27%|██▋       | 1.33G/4.93G [00:21<01:17, 46.4MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  27%|██▋       | 1.34G/4.93G [00:22<01:08, 52.5MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  28%|██▊       | 1.36G/4.93G [00:22<01:03, 56.1MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  28%|██▊       | 1.38G/4.93G [00:22<01:01, 58.0MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  28%|██▊       | 1.39G/4.93G [00:22<00:59, 59.6MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  29%|██▊       | 1.41G/4.93G [00:23<00:54, 64.6MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  29%|██▉       | 1.42G/4.93G [00:23<00:48, 72.3MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  29%|██▉       | 1.44G/4.93G [00:23<00:46, 75.8MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  30%|██▉       | 1.46G/4.93G [00:24<01:12, 47.8MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  29%|██▊       | 1.39G/4.87G [00:24<04:22, 13.3MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.41G/4.87G [00:24<03:18, 17.4MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.42G/4.87G [00:24<02:28, 23.2MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|██▉       | 1.44G/4.87G [00:24<01:57, 29.3MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|██▉       | 1.46G/4.87G [00:25<01:37, 35.0MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.47G/4.87G [00:25<01:21, 42.0MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.50G/4.87G [00:26<01:14, 45.3MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.52G/4.87G [00:26<01:05, 51.5MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  32%|███▏      | 1.60G/4.93G [00:26<01:06, 49.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  29%|██▉       | 1.26G/4.33G [00:26<05:28, 9.34MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.54G/4.87G [00:26<01:08, 48.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  30%|██▉       | 1.28G/4.33G [00:26<04:01, 12.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.55G/4.87G [00:26<01:02, 53.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  30%|██▉       | 1.30G/4.33G [00:27<03:01, 16.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.57G/4.87G [00:27<00:58, 56.6MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.58G/4.87G [00:27<00:50, 65.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  30%|███       | 1.31G/4.33G [00:27<02:22, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.60G/4.87G [00:27<00:48, 67.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  31%|███       | 1.33G/4.33G [00:27<01:52, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.62G/4.87G [00:27<00:43, 74.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  31%|███       | 1.34G/4.33G [00:27<01:34, 31.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.63G/4.87G [00:27<00:45, 71.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  31%|███▏      | 1.36G/4.33G [00:28<01:16, 38.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.65G/4.87G [00:28<00:42, 75.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  32%|███▏      | 1.38G/4.33G [00:28<01:03, 46.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.66G/4.87G [00:28<00:42, 75.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  32%|███▏      | 1.39G/4.33G [00:28<00:56, 51.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.68G/4.87G [00:28<00:48, 65.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  33%|███▎      | 1.41G/4.33G [00:28<00:53, 54.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|███▍      | 1.70G/4.87G [00:28<00:46, 68.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  33%|███▎      | 1.42G/4.33G [00:28<00:51, 57.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|███▌      | 1.71G/4.87G [00:29<00:46, 67.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  33%|███▎      | 1.44G/4.33G [00:29<00:48, 60.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|███▌      | 1.73G/4.87G [00:29<00:45, 68.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  34%|███▎      | 1.46G/4.33G [00:29<00:44, 65.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.74G/4.87G [00:29<00:43, 71.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.76G/4.87G [00:29<00:42, 73.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  37%|███▋      | 1.84G/4.93G [00:29<00:47, 65.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  34%|███▍      | 1.49G/4.33G [00:29<00:43, 64.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  38%|███▊      | 1.86G/4.93G [00:30<00:48, 64.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  35%|███▍      | 1.50G/4.33G [00:30<00:43, 64.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|███▋      | 1.78G/4.87G [00:30<01:00, 51.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.79G/4.87G [00:30<00:51, 59.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  38%|███▊      | 1.89G/4.93G [00:30<00:46, 66.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.81G/4.87G [00:30<00:43, 69.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.82G/4.87G [00:30<00:40, 75.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  36%|███▌      | 1.55G/4.33G [00:30<00:40, 68.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.84G/4.87G [00:31<00:41, 73.0MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  39%|███▉      | 1.94G/4.93G [00:31<00:41, 72.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.86G/4.87G [00:31<00:46, 64.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  40%|███▉      | 1.95G/4.93G [00:31<00:43, 68.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  37%|███▋      | 1.58G/4.33G [00:31<00:49, 55.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.87G/4.87G [00:31<00:47, 63.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  37%|███▋      | 1.60G/4.33G [00:31<00:43, 62.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  39%|███▊      | 1.89G/4.87G [00:31<00:45, 65.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  37%|███▋      | 1.62G/4.33G [00:31<00:44, 61.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.90G/4.87G [00:32<00:44, 66.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  38%|███▊      | 1.63G/4.33G [00:32<00:38, 69.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.92G/4.87G [00:32<00:47, 61.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  38%|███▊      | 1.65G/4.33G [00:32<00:40, 65.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  41%|████      | 2.03G/4.93G [00:32<00:40, 71.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  40%|███▉      | 1.94G/4.87G [00:32<00:45, 64.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  42%|████▏     | 2.05G/4.93G [00:32<00:40, 70.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  40%|████      | 1.95G/4.87G [00:32<00:45, 63.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  42%|████▏     | 2.06G/4.93G [00:33<00:45, 63.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  40%|████      | 1.97G/4.87G [00:33<00:42, 68.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  39%|███▉      | 1.71G/4.33G [00:33<00:31, 83.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  42%|████▏     | 2.08G/4.93G [00:33<00:45, 63.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|████      | 1.98G/4.87G [00:33<00:47, 60.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  42%|████▏     | 2.10G/4.93G [00:33<00:44, 63.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.00G/4.87G [00:33<00:44, 65.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  43%|████▎     | 2.11G/4.93G [00:33<00:40, 70.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|████▏     | 2.02G/4.87G [00:33<00:42, 67.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  41%|████      | 1.76G/4.33G [00:33<00:36, 70.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.03G/4.87G [00:34<00:41, 67.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.05G/4.87G [00:34<00:39, 71.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  43%|████▎     | 2.14G/4.93G [00:34<00:43, 63.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  41%|████▏     | 1.79G/4.33G [00:34<00:33, 76.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.06G/4.87G [00:34<00:41, 67.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.08G/4.87G [00:34<00:39, 71.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  42%|████▏     | 1.82G/4.33G [00:34<00:31, 80.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.10G/4.87G [00:34<00:39, 70.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  42%|████▏     | 1.84G/4.33G [00:34<00:30, 82.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  44%|████▍     | 2.19G/4.93G [00:34<00:41, 65.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.11G/4.87G [00:35<00:41, 66.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  45%|████▍     | 2.21G/4.93G [00:35<00:42, 64.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  44%|████▎     | 2.13G/4.87G [00:35<00:38, 71.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  45%|████▌     | 2.22G/4.93G [00:35<00:40, 66.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.14G/4.87G [00:35<00:38, 71.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  45%|████▌     | 2.24G/4.93G [00:35<00:41, 64.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.16G/4.87G [00:35<00:42, 63.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|████▍     | 2.18G/4.87G [00:36<00:40, 66.0MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  46%|████▌     | 2.27G/4.93G [00:36<00:38, 69.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  45%|████▍     | 2.19G/4.87G [00:36<00:39, 68.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  45%|████▍     | 1.94G/4.33G [00:36<00:40, 59.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.21G/4.87G [00:36<00:40, 65.5MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.22G/4.87G [00:36<00:40, 66.1MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  47%|████▋     | 2.32G/4.93G [00:36<00:38, 67.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.24G/4.87G [00:37<00:42, 62.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  47%|████▋     | 2.34G/4.93G [00:37<00:37, 69.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  45%|████▌     | 1.97G/4.33G [00:37<00:44, 53.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  48%|████▊     | 2.35G/4.93G [00:37<00:37, 69.7MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  48%|████▊     | 2.37G/4.93G [00:37<00:37, 67.9MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  48%|████▊     | 2.38G/4.93G [00:37<00:35, 71.1MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  49%|████▊     | 2.40G/4.93G [00:37<00:32, 78.8MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  49%|████▉     | 2.42G/4.93G [00:38<00:31, 79.0MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  46%|████▋     | 2.26G/4.87G [00:38<01:39, 26.2MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.27G/4.87G [00:38<01:24, 30.8MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.29G/4.87G [00:39<01:07, 38.4MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.30G/4.87G [00:39<00:55, 46.5MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.34G/4.87G [00:39<00:43, 58.0MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  51%|█████     | 2.51G/4.93G [00:39<00:35, 68.4MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.35G/4.87G [00:39<00:46, 53.8MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.38G/4.87G [00:40<00:41, 59.9MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.42G/4.87G [00:40<00:35, 69.5MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.43G/4.87G [00:41<00:32, 74.2MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.45G/4.87G [00:41<00:34, 70.9MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.46G/4.87G [00:41<00:35, 68.8MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.48G/4.87G [00:41<00:31, 75.1MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.50G/4.87G [00:41<00:32, 73.3MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  54%|█████▍    | 2.66G/4.93G [00:41<00:32, 70.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  46%|████▌     | 1.98G/4.33G [00:42<04:11, 9.33MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.51G/4.87G [00:42<00:35, 66.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  46%|████▌     | 2.00G/4.33G [00:42<03:17, 11.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  54%|█████▍    | 2.69G/4.93G [00:42<00:26, 84.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.53G/4.87G [00:42<00:37, 63.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  55%|█████▍    | 2.70G/4.93G [00:42<00:32, 69.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  47%|████▋     | 2.02G/4.33G [00:42<02:08, 18.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.54G/4.87G [00:42<00:38, 61.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  47%|████▋     | 2.03G/4.33G [00:42<01:35, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.56G/4.87G [00:43<00:38, 59.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  47%|████▋     | 2.05G/4.33G [00:43<01:14, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.58G/4.87G [00:43<00:36, 63.7MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  56%|█████▌    | 2.75G/4.93G [00:43<00:33, 64.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.59G/4.87G [00:43<00:39, 57.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  56%|█████▌    | 2.77G/4.93G [00:43<00:32, 67.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  48%|████▊     | 2.08G/4.33G [00:43<00:53, 41.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|█████▎    | 2.61G/4.87G [00:43<00:38, 58.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.62G/4.87G [00:44<00:35, 62.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  57%|█████▋    | 2.80G/4.93G [00:44<00:31, 68.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  49%|████▉     | 2.11G/4.33G [00:44<00:39, 56.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.64G/4.87G [00:44<00:37, 60.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.66G/4.87G [00:44<00:33, 66.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  57%|█████▋    | 2.83G/4.93G [00:44<00:30, 68.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  55%|█████▍    | 2.67G/4.87G [00:44<00:34, 63.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  50%|████▉     | 2.16G/4.33G [00:44<00:36, 59.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.69G/4.87G [00:45<00:35, 62.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  50%|█████     | 2.18G/4.33G [00:45<00:36, 59.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.70G/4.87G [00:45<00:32, 65.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  51%|█████     | 2.19G/4.33G [00:45<00:36, 59.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.72G/4.87G [00:45<00:33, 64.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  51%|█████     | 2.21G/4.33G [00:45<00:32, 66.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.74G/4.87G [00:45<00:33, 63.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  51%|█████▏    | 2.22G/4.33G [00:45<00:29, 70.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|█████▋    | 2.75G/4.87G [00:46<00:31, 67.6MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  59%|█████▉    | 2.93G/4.93G [00:46<00:26, 74.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.77G/4.87G [00:46<00:31, 65.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  60%|█████▉    | 2.94G/4.93G [00:46<00:28, 70.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.78G/4.87G [00:46<00:29, 70.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.80G/4.87G [00:46<00:27, 74.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  52%|█████▏    | 2.27G/4.33G [00:46<00:32, 63.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  60%|██████    | 2.98G/4.93G [00:46<00:27, 70.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.82G/4.87G [00:46<00:29, 69.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.83G/4.87G [00:47<00:27, 73.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  53%|█████▎    | 2.30G/4.33G [00:47<00:32, 61.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.85G/4.87G [00:47<00:31, 65.0MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.86G/4.87G [00:47<00:27, 72.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.88G/4.87G [00:47<00:26, 74.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  54%|█████▍    | 2.34G/4.33G [00:47<00:39, 51.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.90G/4.87G [00:48<00:26, 73.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  54%|█████▍    | 2.35G/4.33G [00:48<00:31, 63.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  62%|██████▏   | 3.06G/4.93G [00:48<00:29, 64.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  60%|█████▉    | 2.91G/4.87G [00:48<00:30, 64.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  62%|██████▏   | 3.06G/4.93G [00:48<00:34, 53.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  60%|██████    | 2.93G/4.87G [00:48<00:28, 68.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 2.96G/4.87G [00:49<00:29, 64.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 2.98G/4.87G [00:49<00:27, 69.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  56%|█████▌    | 2.42G/4.33G [00:49<00:31, 60.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  61%|██████▏   | 2.99G/4.87G [00:49<00:27, 69.1MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  63%|██████▎   | 3.09G/4.93G [00:49<00:54, 33.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.01G/4.87G [00:49<00:27, 66.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.02G/4.87G [00:50<00:28, 64.2MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  63%|██████▎   | 3.12G/4.93G [00:50<00:40, 44.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.04G/4.87G [00:50<00:28, 65.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  64%|██████▎   | 3.14G/4.93G [00:50<00:37, 48.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.06G/4.87G [00:50<00:29, 61.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  64%|██████▍   | 3.15G/4.93G [00:50<00:32, 54.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.07G/4.87G [00:50<00:27, 65.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  64%|██████▍   | 3.17G/4.93G [00:50<00:30, 57.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.09G/4.87G [00:50<00:26, 67.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  58%|█████▊    | 2.51G/4.33G [00:51<00:28, 63.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  64%|██████▎   | 3.10G/4.87G [00:51<00:24, 71.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  58%|█████▊    | 2.53G/4.33G [00:51<00:26, 67.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.12G/4.87G [00:51<00:25, 69.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.14G/4.87G [00:51<00:23, 73.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  65%|██████▌   | 3.22G/4.93G [00:51<00:28, 59.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.15G/4.87G [00:51<00:22, 76.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  66%|██████▌   | 3.23G/4.93G [00:51<00:25, 66.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.17G/4.87G [00:52<00:24, 71.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  66%|██████▌   | 3.25G/4.93G [00:52<00:28, 58.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  65%|██████▌   | 3.18G/4.87G [00:52<00:22, 73.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  60%|██████    | 2.61G/4.33G [00:52<00:23, 74.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.20G/4.87G [00:52<00:21, 77.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  61%|██████    | 2.62G/4.33G [00:52<00:22, 75.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.22G/4.87G [00:52<00:24, 67.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  61%|██████    | 2.64G/4.33G [00:52<00:22, 75.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  67%|██████▋   | 3.30G/4.93G [00:52<00:24, 67.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  61%|██████▏   | 2.66G/4.33G [00:52<00:21, 79.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  66%|██████▋   | 3.23G/4.87G [00:53<00:26, 61.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  62%|██████▏   | 2.67G/4.33G [00:53<00:21, 78.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.25G/4.87G [00:53<00:25, 64.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  62%|██████▏   | 2.69G/4.33G [00:53<00:18, 87.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  68%|██████▊   | 3.34G/4.93G [00:53<00:21, 75.5MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.26G/4.87G [00:53<00:25, 62.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.28G/4.87G [00:53<00:23, 67.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.30G/4.87G [00:54<00:24, 64.2MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  69%|██████▉   | 3.39G/4.93G [00:54<00:20, 73.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.31G/4.87G [00:54<00:20, 74.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  69%|██████▉   | 3.40G/4.93G [00:54<00:18, 82.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  63%|██████▎   | 2.73G/4.33G [00:54<00:23, 67.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  69%|██████▉   | 3.41G/4.93G [00:54<00:19, 77.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.32G/4.87G [00:54<00:27, 57.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  69%|██████▉   | 3.42G/4.93G [00:54<00:21, 70.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  64%|██████▎   | 2.75G/4.33G [00:54<00:25, 61.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.33G/4.87G [00:54<00:29, 52.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  69%|██████▊   | 3.34G/4.87G [00:54<00:26, 58.6MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  70%|███████   | 3.46G/4.93G [00:54<00:20, 71.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.36G/4.87G [00:55<00:25, 60.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  70%|███████   | 3.47G/4.93G [00:55<00:20, 69.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.38G/4.87G [00:55<00:24, 60.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  71%|███████   | 3.49G/4.93G [00:55<00:22, 63.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  65%|██████▌   | 2.82G/4.33G [00:55<00:25, 58.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  70%|██████▉   | 3.39G/4.87G [00:55<00:26, 56.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  65%|██████▌   | 2.83G/4.33G [00:55<00:23, 64.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  66%|██████▌   | 2.85G/4.33G [00:55<00:21, 67.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  70%|██████▉   | 3.41G/4.87G [00:55<00:24, 59.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.42G/4.87G [00:56<00:25, 57.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  72%|███████▏  | 3.54G/4.93G [00:56<00:24, 56.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.44G/4.87G [00:56<00:23, 61.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  72%|███████▏  | 3.55G/4.93G [00:56<00:22, 61.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.46G/4.87G [00:56<00:20, 68.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  72%|███████▏  | 3.57G/4.93G [00:56<00:20, 67.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.47G/4.87G [00:56<00:20, 68.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.49G/4.87G [00:57<00:20, 68.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  68%|██████▊   | 2.93G/4.33G [00:57<00:23, 59.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.50G/4.87G [00:57<00:19, 68.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  68%|██████▊   | 2.94G/4.33G [00:57<00:20, 67.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  73%|███████▎  | 3.62G/4.93G [00:57<00:19, 67.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.52G/4.87G [00:57<00:20, 66.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.54G/4.87G [00:57<00:19, 70.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  69%|██████▊   | 2.98G/4.33G [00:57<00:20, 67.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.55G/4.87G [00:58<00:17, 74.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  69%|██████▉   | 2.99G/4.33G [00:58<00:19, 70.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  74%|███████▍  | 3.66G/4.93G [00:58<00:18, 70.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.57G/4.87G [00:58<00:17, 72.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  75%|███████▍  | 3.68G/4.93G [00:58<00:18, 68.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  74%|███████▎  | 3.58G/4.87G [00:58<00:17, 72.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  75%|███████▍  | 3.70G/4.93G [00:58<00:18, 68.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.60G/4.87G [00:58<00:16, 76.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  71%|███████   | 3.06G/4.33G [00:58<00:16, 76.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.62G/4.87G [00:58<00:17, 73.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  71%|███████   | 3.07G/4.33G [00:59<00:17, 71.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|███████▍  | 3.63G/4.87G [00:59<00:18, 68.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  75%|███████▍  | 3.65G/4.87G [00:59<00:16, 72.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  76%|███████▌  | 3.74G/4.93G [00:59<00:18, 63.6MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|███████▌  | 3.66G/4.87G [00:59<00:16, 71.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  72%|███████▏  | 3.10G/4.33G [00:59<00:18, 64.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|███████▌  | 3.68G/4.87G [00:59<00:17, 69.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  72%|███████▏  | 3.12G/4.33G [00:59<00:20, 57.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.70G/4.87G [01:00<00:17, 69.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  72%|███████▏  | 3.14G/4.33G [01:00<00:19, 61.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.71G/4.87G [01:00<00:17, 67.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  73%|███████▎  | 3.15G/4.33G [01:00<00:19, 60.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  78%|███████▊  | 3.82G/4.93G [01:00<00:17, 65.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  73%|███████▎  | 3.17G/4.33G [01:00<00:19, 60.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  78%|███████▊  | 3.84G/4.93G [01:00<00:15, 69.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  74%|███████▎  | 3.18G/4.33G [01:00<00:17, 65.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  78%|███████▊  | 3.86G/4.93G [01:01<00:17, 59.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  74%|███████▍  | 3.20G/4.33G [01:01<00:18, 60.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  78%|███████▊  | 3.87G/4.93G [01:01<00:15, 66.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  74%|███████▍  | 3.22G/4.33G [01:01<00:17, 64.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  79%|███████▉  | 3.89G/4.93G [01:01<00:14, 71.3MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  79%|███████▉  | 3.90G/4.93G [01:01<00:13, 74.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  75%|███████▍  | 3.23G/4.33G [01:01<00:16, 66.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  79%|███████▉  | 3.92G/4.93G [01:01<00:14, 69.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  75%|███████▍  | 3.25G/4.33G [01:01<00:16, 64.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  80%|███████▉  | 3.94G/4.93G [01:02<00:14, 71.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  75%|███████▌  | 3.26G/4.33G [01:02<00:17, 61.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  80%|████████  | 3.95G/4.93G [01:02<00:14, 69.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  76%|███████▌  | 3.28G/4.33G [01:02<00:17, 59.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  80%|████████  | 3.97G/4.93G [01:02<00:13, 70.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  76%|███████▌  | 3.30G/4.33G [01:02<00:15, 64.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  81%|████████  | 3.98G/4.93G [01:02<00:13, 71.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  76%|███████▋  | 3.31G/4.33G [01:02<00:14, 68.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  81%|████████  | 4.00G/4.93G [01:02<00:12, 75.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  77%|███████▋  | 3.33G/4.33G [01:03<00:15, 64.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  76%|███████▋  | 3.73G/4.87G [01:03<01:16, 15.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  77%|███████▋  | 3.34G/4.33G [01:03<00:15, 64.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.74G/4.87G [01:03<00:58, 19.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.76G/4.87G [01:03<00:44, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  82%|████████▏ | 4.05G/4.93G [01:03<00:13, 63.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.79G/4.87G [01:04<00:28, 38.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  82%|████████▏ | 4.06G/4.93G [01:04<00:16, 52.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  78%|███████▊  | 3.39G/4.33G [01:04<00:15, 58.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.81G/4.87G [01:04<00:24, 44.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  79%|███████▊  | 3.41G/4.33G [01:04<00:14, 64.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.82G/4.87G [01:04<00:19, 54.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  79%|███████▉  | 3.42G/4.33G [01:04<00:13, 69.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  79%|███████▊  | 3.83G/4.87G [01:04<00:19, 52.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  79%|███████▉  | 3.44G/4.33G [01:04<00:12, 72.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.84G/4.87G [01:04<00:20, 50.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  80%|███████▉  | 3.46G/4.33G [01:05<00:11, 74.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.86G/4.87G [01:05<00:19, 53.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.87G/4.87G [01:05<00:16, 60.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  84%|████████▍ | 4.14G/4.93G [01:05<00:14, 54.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  80%|███████▉  | 3.89G/4.87G [01:05<00:16, 61.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  84%|████████▍ | 4.16G/4.93G [01:05<00:13, 57.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 3.90G/4.87G [01:05<00:16, 60.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  85%|████████▍ | 4.18G/4.93G [01:05<00:12, 60.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 3.92G/4.87G [01:06<00:14, 65.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  85%|████████▍ | 4.19G/4.93G [01:06<00:11, 62.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 3.94G/4.87G [01:06<00:14, 62.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 3.95G/4.87G [01:06<00:13, 67.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  82%|████████▏ | 3.55G/4.33G [01:06<00:12, 62.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  86%|████████▌ | 4.22G/4.93G [01:06<00:11, 59.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  81%|████████▏ | 3.97G/4.87G [01:06<00:13, 67.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 3.98G/4.87G [01:07<00:12, 69.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  83%|████████▎ | 3.58G/4.33G [01:07<00:11, 66.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  86%|████████▋ | 4.26G/4.93G [01:07<00:10, 62.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.00G/4.87G [01:07<00:13, 65.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.02G/4.87G [01:07<00:13, 63.7MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.03G/4.87G [01:07<00:11, 71.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  83%|████████▎ | 3.62G/4.33G [01:07<00:16, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.05G/4.87G [01:08<00:12, 64.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  84%|████████▍ | 3.63G/4.33G [01:08<00:13, 49.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.06G/4.87G [01:08<00:12, 66.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  84%|████████▍ | 3.65G/4.33G [01:08<00:11, 59.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  88%|████████▊ | 4.34G/4.93G [01:08<00:08, 73.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  85%|████████▍ | 3.66G/4.33G [01:08<00:09, 66.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|████████▎ | 4.08G/4.87G [01:08<00:14, 53.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  85%|████████▍ | 3.68G/4.33G [01:08<00:10, 64.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.10G/4.87G [01:08<00:13, 57.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  85%|████████▌ | 3.70G/4.33G [01:08<00:09, 66.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.11G/4.87G [01:09<00:14, 51.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  85%|████████▍ | 4.13G/4.87G [01:09<00:13, 54.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  89%|████████▉ | 4.38G/4.93G [01:09<00:13, 40.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  86%|████████▋ | 3.74G/4.33G [01:09<00:08, 69.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  87%|████████▋ | 3.76G/4.33G [01:09<00:07, 74.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  89%|████████▉ | 4.40G/4.93G [01:09<00:11, 45.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  87%|████████▋ | 3.78G/4.33G [01:09<00:07, 78.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.14G/4.87G [01:10<00:17, 41.7MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  90%|████████▉ | 4.43G/4.93G [01:10<00:08, 58.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  88%|████████▊ | 3.79G/4.33G [01:10<00:07, 73.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  85%|████████▌ | 4.16G/4.87G [01:10<00:15, 45.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  90%|█████████ | 4.45G/4.93G [01:10<00:07, 62.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.17G/4.87G [01:10<00:12, 55.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  90%|█████████ | 4.46G/4.93G [01:10<00:06, 72.3MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  91%|█████████ | 4.47G/4.93G [01:10<00:06, 72.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.18G/4.87G [01:10<00:13, 53.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  89%|████████▊ | 3.84G/4.33G [01:10<00:06, 70.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  86%|████████▌ | 4.19G/4.87G [01:10<00:12, 54.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  89%|████████▉ | 3.85G/4.33G [01:10<00:05, 83.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  86%|████████▋ | 4.21G/4.87G [01:10<00:09, 68.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  89%|████████▉ | 3.86G/4.33G [01:11<00:05, 82.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  86%|████████▋ | 4.21G/4.87G [01:11<00:10, 62.9MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  91%|█████████▏| 4.51G/4.93G [01:11<00:06, 62.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.22G/4.87G [01:11<00:11, 58.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  92%|█████████▏| 4.53G/4.93G [01:11<00:05, 76.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.24G/4.87G [01:11<00:08, 71.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  92%|█████████▏| 4.53G/4.93G [01:11<00:05, 69.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.25G/4.87G [01:11<00:09, 64.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  87%|████████▋ | 4.26G/4.87G [01:11<00:10, 57.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  92%|█████████▏| 4.54G/4.93G [01:11<00:07, 52.7MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  91%|█████████ | 3.92G/4.33G [01:12<00:06, 65.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.27G/4.87G [01:12<00:10, 55.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  91%|█████████ | 3.94G/4.33G [01:12<00:06, 65.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.29G/4.87G [01:12<00:10, 53.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  91%|█████████▏| 3.95G/4.33G [01:12<00:05, 69.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  93%|█████████▎| 4.59G/4.93G [01:12<00:05, 66.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  88%|████████▊ | 4.30G/4.87G [01:12<00:10, 56.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  89%|████████▊ | 4.32G/4.87G [01:12<00:08, 66.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  92%|█████████▏| 3.98G/4.33G [01:12<00:04, 72.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  94%|█████████▎| 4.62G/4.93G [01:12<00:04, 71.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  92%|█████████▏| 4.00G/4.33G [01:13<00:04, 70.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.34G/4.87G [01:13<00:08, 60.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  93%|█████████▎| 4.02G/4.33G [01:13<00:04, 66.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  89%|████████▉ | 4.35G/4.87G [01:13<00:08, 61.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  90%|████████▉ | 4.37G/4.87G [01:13<00:08, 61.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  90%|████████▉ | 4.38G/4.87G [01:13<00:07, 64.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  93%|█████████▎| 4.05G/4.33G [01:13<00:04, 63.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  90%|█████████ | 4.40G/4.87G [01:14<00:06, 78.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  94%|█████████▍| 4.06G/4.33G [01:14<00:03, 75.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  90%|█████████ | 4.41G/4.87G [01:14<00:06, 71.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  91%|█████████ | 4.42G/4.87G [01:14<00:06, 67.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  94%|█████████▍| 4.08G/4.33G [01:14<00:04, 61.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  96%|█████████▌| 4.72G/4.93G [01:14<00:03, 61.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  91%|█████████ | 4.43G/4.87G [01:14<00:06, 63.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  91%|█████████ | 4.45G/4.87G [01:14<00:05, 73.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  95%|█████████▍| 4.11G/4.33G [01:14<00:03, 68.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.46G/4.87G [01:15<00:05, 68.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  95%|█████████▌| 4.13G/4.33G [01:15<00:03, 65.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.48G/4.87G [01:15<00:06, 64.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  96%|█████████▌| 4.14G/4.33G [01:15<00:02, 63.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  92%|█████████▏| 4.50G/4.87G [01:15<00:05, 64.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  97%|█████████▋| 4.78G/4.93G [01:15<00:02, 58.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  96%|█████████▋| 4.18G/4.33G [01:15<00:01, 80.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.51G/4.87G [01:15<00:05, 62.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  97%|█████████▋| 4.19G/4.33G [01:15<00:02, 66.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.53G/4.87G [01:16<00:05, 64.2MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  97%|█████████▋| 4.21G/4.33G [01:16<00:01, 72.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  98%|█████████▊| 4.83G/4.93G [01:16<00:01, 60.6MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  93%|█████████▎| 4.54G/4.87G [01:16<00:06, 52.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  98%|█████████▊| 4.22G/4.33G [01:16<00:01, 59.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  94%|█████████▎| 4.56G/4.87G [01:16<00:05, 57.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  98%|█████████▊| 4.24G/4.33G [01:16<00:01, 65.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  99%|█████████▉| 4.88G/4.93G [01:16<00:00, 68.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.58G/4.87G [01:17<00:05, 52.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors:  99%|█████████▉| 4.90G/4.93G [01:17<00:00, 69.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  94%|█████████▍| 4.59G/4.87G [01:17<00:05, 54.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors: 100%|█████████▉| 4.91G/4.93G [01:17<00:00, 69.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors:  99%|█████████▉| 4.29G/4.33G [01:17<00:00, 65.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00004.safetensors: 100%|█████████▉| 4.93G/4.93G [01:17<00:00, 70.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors: 100%|██████████| 4.93G/4.93G [01:17<00:00, 63.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model-00003-of-00004.safetensors: 100%|██████████| 4.33G/4.33G [01:18<00:00, 55.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors: 100%|██████████| 4.87G/4.87G [01:21<00:00, 60.0MB/s]\n",
      "\n",
      "\n",
      "\n",
      "Upload 4 LFS files: 100%|██████████| 4/4 [01:21<00:00, 20.39s/it]\u001b[A\u001b[A\u001b[A\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "2024-09-15:17:56:53,878 WARNING  [hf_api.py:3800] No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/huggingscientist10/ORPO-EdgeRunner-Tactical-7B-GSM8K/commit/faa4c01af8ec7d8adca222d5f5d99ebdc031fe23', commit_message='Upload tokenizer', commit_description='', oid='faa4c01af8ec7d8adca222d5f5d99ebdc031fe23', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flush memory\n",
    "try:\n",
    "    del model2\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "# Reload tokenizer and model\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(model2_name)\n",
    "model2 = AutoModelForCausalLM.from_pretrained(\n",
    "    model2_name,\n",
    "    return_dict=True,\n",
    "    # quantization_config=bnb_config, # 4-bit breaks model text generation in this model\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation,\n",
    ")\n",
    "model2, tokenizer2 = setup_chat_format(model2, tokenizer2)\n",
    "\n",
    "# Merge adapter with base model\n",
    "merged_model = PeftModel.from_pretrained(model2, \"./EdgeRunner_FT_Adapters/\")\n",
    "merged_model = merged_model.merge_and_unload()\n",
    "\n",
    "merged_model.push_to_hub(tuned_model2_name, use_temp_dir=True, token = \"\") # write HF token\n",
    "tokenizer2.push_to_hub(tuned_model2_name, use_temp_dir=True, token = \"\") # write HF token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b00e25-2780-402d-9fdd-c6aace318c05",
   "metadata": {},
   "source": [
    "#### MODEL DEBATE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd811f2a-79bb-41f5-a6eb-ffeeffb31525",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Load Fine-Tuned Models #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52ad9134-2ca9-4663-9e7a-355c401d8b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:03<00:00, 15.96s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [01:52<00:00, 16.14s/it]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del model2\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "model1_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "model2_name = \"edgerunner-ai/EdgeRunner-Tactical-7B\"\n",
    "# model1_name = \"huggingscientist10/ORPO-Llama-3.1-8B-Instruct-GSM8K\"\n",
    "# model2_name = \"huggingscientist10/ORPO-EdgeRunner-Tactical-7B-GSM8K\"\n",
    "\n",
    "# Initialize Llama\n",
    "model1 = AutoModelForCausalLM.from_pretrained(model1_name, quantization_config=bnb_config,attn_implementation=attn_implementation,\n",
    "                device_map=\"auto\", cache_dir = './models/')\n",
    "\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(model1_name)\n",
    "# tokenizer1.pad_token = tokenizer1.eos_token # No need, pad is already like that\n",
    "# model1, tokenizer1 = setup_chat_format(model1, tokenizer1)\n",
    "\n",
    "\n",
    "# Initialize EdgeRunner\n",
    "model2 = AutoModelForCausalLM.from_pretrained(model2_name,attn_implementation=attn_implementation,\n",
    "                torch_dtype=torch.bfloat16, device_map=\"auto\", cache_dir = './models/')\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(model2_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f4a2e61-87b6-42b8-af06-cb3305afcf2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 63/100 questions. Current accuracy: 65.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# CollaborativeModel class\n",
    "class CollaborativeModel:\n",
    "    def __init__(self, model1, tokenizer1, model2, tokenizer2):\n",
    "        self.model1 = model1\n",
    "        self.tokenizer1 = tokenizer1\n",
    "        \n",
    "        self.model2 = model2\n",
    "        self.tokenizer2 = tokenizer2\n",
    "\n",
    "        self.device1 = torch.device(\"cuda\")\n",
    "        self.device2 = torch.device(\"cuda\")\n",
    "\n",
    "    def generate_response(self, model, tokenizer, prompt, device, max_length=1024):\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        outputs = model.generate(**inputs, max_new_tokens=max_length, num_return_sequences=1, \n",
    "                                 do_sample=False, temperature=0.0)\n",
    "        \n",
    "        # Exclude the prompt tokens from the generated output\n",
    "        prompt_token_length = inputs['input_ids'].shape[1]\n",
    "        return tokenizer.decode(outputs[0][prompt_token_length:], skip_special_tokens=True)\n",
    "\n",
    "    def debate(self, question, num_rounds=2):\n",
    "    #     # Initial instruction setup for both models\n",
    "        discussion = f\"\"\"<|begin_of_text|><|start_header_id|>Instruction<|end_header_id|>\n",
    "Llama will provide step-by-step answers to the given question, and EdgeRunner will provide different approaches, in order for both to converge to the correct solution.\n",
    "The approaches have to have proper calculations, arithmetic and assumptions, in a clear and concise fashion.<|eot_id|>\n",
    "In the end, Llama will correct and state the final answer as a single scalar value.<|start_header_id|>Question:<|end_header_id|>\n",
    "{question}<|eot_id|>\n",
    "<|start_header_id|>Answer:<|end_header_id|>\"\"\"\n",
    "        # Llama's initial step\n",
    "        prompt1 = f\"{discussion}\\nLlama:\"# (Initial problem analysis and proposed solution):\"\n",
    "        response1 = self.generate_response(self.model1, self.tokenizer1, prompt1, self.device1)\n",
    "        discussion += f\"\\nLlama: {response1.strip()}\\n\\n\"\n",
    "\n",
    "        for round in range(num_rounds):\n",
    "            # EdgeRunner's critical evaluation and next step\n",
    "            prompt2 = f\"{discussion}\\nEdgeRunner:\"# (Critique and Next Step):\\nLlama proposed the step above. Critically analyze it. If it's correct, provide the resulting solution. If it's incorrect, provide the correct step.\"\n",
    "            response2 = self.generate_response(self.model2, self.tokenizer2, prompt2, self.device2)\n",
    "            discussion += f\"\\nEdgeRunner: {response2.strip()}\\n\\n\"\n",
    "\n",
    "            # Llama's critique and next step\n",
    "            prompt3 = f\"{discussion}\\nLlama:\"# (Critique and Next Step):\\nEdgeRunner proposed the step above. Critically analyze it. If it's correct, provide the resulting solution. If it's incorrect, provide the correct step.\"\n",
    "            response3 = self.generate_response(self.model1, self.tokenizer1, prompt3, self.device1)\n",
    "            discussion += f\"\\nLlama: {response3.strip()}\\n\\n\"\n",
    "\n",
    "        # Final answer synthesis\n",
    "        final_prompt = f\"{discussion}\\nLlama (Final answer):\\n\"#Based on the critique and discussion above, Llama will now provide the final, verified answer as a single scalar value.\"\n",
    "        final_answer = self.generate_response(self.model1, self.tokenizer1, final_prompt, self.device1, max_length=100)\n",
    "\n",
    "        return discussion # final_answer\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_collaborative_model(model, dataset, num_samples=100, output_file=\"result.txt\"):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    with open(output_file, \"a\") as f:\n",
    "        for i, example in enumerate(dataset.select(range(num_samples)), 1):\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            question = example['question']\n",
    "            true_answer = example['answer']\n",
    "            \n",
    "            debate_result = model.debate(question)\n",
    "            final_answer = clean_answer(debate_result)\n",
    "            \n",
    "            if clean_answer(true_answer) == final_answer:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "            current_accuracy = correct / total\n",
    "            accuracies.append(current_accuracy)\n",
    "            \n",
    "            print(f\"{debate_result}\\n\\n\")\n",
    "            f.write(f\"Question {i}:\\n{question}\\n\\n\")\n",
    "            f.write(f\"Debate result:\\n{debate_result}\\n\\n\")\n",
    "            f.write(f\"True answer: {true_answer}\\n\")\n",
    "            f.write(f\"Final answer: {final_answer}\\n\")\n",
    "            f.write(f\"Current accuracy: {100*current_accuracy:.2f}%\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\\n\")\n",
    "            f.flush()\n",
    "            \n",
    "            # Clear the output and redraw the plot\n",
    "            clear_output(wait=True)\n",
    "            plt.clf()\n",
    "            plt.plot(range(1, i+1), accuracies, 'b-')\n",
    "            plt.title(\"Accuracy Over Time\")\n",
    "            plt.xlabel(\"Number of Questions\")\n",
    "            plt.ylabel(\"Accuracy\")\n",
    "            plt.show()\n",
    "            # display(plt.gcf())\n",
    "            print(f\"Processed {i}/{num_samples} questions. Current accuracy: {100*current_accuracy:.2f}%\")\n",
    "    \n",
    "    # Save the final plot\n",
    "    plt.savefig(\"final_accuracy_plot.png\")\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "def clean_answer(text):\n",
    "    # Remove commas from the text\n",
    "    cleaned_text = text.replace(',', '')\n",
    "    # Find all digit sequences in the cleaned text\n",
    "    numbers = re.findall(r'\\d+', cleaned_text)\n",
    "    # Return the last number found, or None if no number is found\n",
    "    return numbers[-1] if numbers else None\n",
    "\n",
    "\n",
    "def parse_final_answer(evaluation):\n",
    "    try:\n",
    "        answer = evaluation.split('Final answer: ')[1]\n",
    "        return clean_answer(answer)\n",
    "    except:\n",
    "        return 'NA' # Return NA if a final answer could not be found\n",
    "\n",
    "\n",
    "\n",
    "# Load the GSM8K dataset\n",
    "dataset = load_dataset(\"gsm8k\", \"main\")\n",
    "\n",
    "# Initialize the collaborative model (assuming model1, tokenizer1, model2, tokenizer2 are defined)\n",
    "model = CollaborativeModel(model1, tokenizer1, model2, tokenizer2)\n",
    "\n",
    "# Evaluate the collaborative model\n",
    "accuracy = evaluate_collaborative_model(model, dataset[\"test\"])\n",
    "print(f\"Final accuracy of the collaborative model: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - Pytorch and Tensorflow",
   "language": "python",
   "name": "python38-azureml-pt-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
